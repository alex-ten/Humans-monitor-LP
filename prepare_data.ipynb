{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-25T14:34:58.242714Z",
     "start_time": "2020-10-25T14:34:58.237945Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import path\n",
    "from IPython.display import display\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Combine raw data files\n",
    "Concatenate raw data and codify participant IDs into a more readable form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Open main files and combine them\n",
    "df = pd.concat(\n",
    "    (\n",
    "        pd.read_csv('data/raw/ig_main.csv'),\n",
    "        pd.read_csv('data/raw/eg_main.csv')\n",
    "    )\n",
    ")\n",
    "\n",
    "# Codify subject IDs\n",
    "df.loc[:, 'sid'] = df.sid.astype('category').cat.codes\n",
    "\n",
    "# Save combined data\n",
    "df.to_csv(path.join(data_path, 'combined_main.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-25T14:17:09.510337Z",
     "start_time": "2020-10-25T14:17:09.505646Z"
    },
    "heading_collapsed": true
   },
   "source": [
    "# Exclude outliers\n",
    "Exclude outliers based on allocation variance and response bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-25T22:27:14.939833Z",
     "start_time": "2020-10-25T22:27:07.834440Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def make_clean_dataset(input_data_path, save_path, **kwargs):\n",
    "    # Define a response bias function\n",
    "    def rbf(x):\n",
    "        _, response_counts = np.unique(x.response, return_counts=True)\n",
    "        return np.max(response_counts) / np.sum(response_counts)\n",
    "\n",
    "\n",
    "    # Open combined data file\n",
    "    df = pd.read_csv(input_data_path, index_col=None).set_index('sid')\n",
    "\n",
    "    # Initialize columns to record values of interest\n",
    "    df['alloc_var'], df['resp_bias'] = 0, 0\n",
    "\n",
    "    # Calculate values of interest\n",
    "    activities = ('A1', 'A2', 'A3', 'A4')\n",
    "    for sid, sdf in tqdm(df.groupby(by='sid'), desc='Progress: '):\n",
    "        # Allocation variance\n",
    "        counts = [sum(sdf.activity == i) for i in activities]\n",
    "        allocation_variance = np.std(counts)\n",
    "        df.loc[sid, 'alloc_var'] = allocation_variance\n",
    "\n",
    "        # Response bias\n",
    "        response_bias = sdf.groupby('family').apply(rbf).mean()\n",
    "        df.loc[sid, 'resp_bias'] = response_bias\n",
    "\n",
    "    # Detect high allocation variance and response bias\n",
    "    df_ = df.reset_index().groupby('sid').head(1).reset_index()\n",
    "    df_['high_av'] = df_.alloc_var >= kwargs['av_crit']\n",
    "    df_['high_rb'] = np.logical_and(df_.resp_bias > df_.resp_bias.mean() + kwargs['rb_crit'] * df_.resp_bias.std(), ~df_.high_av)\n",
    "\n",
    "    display(df_.groupby(by='group')[['high_av', 'high_rb']].sum().astype(int))\n",
    "    print('Found {} outliers'.format(np.logical_or(df_.high_av, df_.high_rb).sum()))\n",
    "\n",
    "    # Exclude outliers\n",
    "    outlier = df_.loc[df_.high_av | df_.high_rb, 'sid']\n",
    "    df = df.loc[~df.index.isin(outlier), :]\n",
    "    display(df.reset_index().groupby(by='group')['sid'].nunique())\n",
    "\n",
    "    # Save data\n",
    "    if save_path:\n",
    "        df.reset_index().to_csv(save_path, index=False)\n",
    "    \n",
    "\n",
    "if 1:\n",
    "    make_clean_dataset(\n",
    "        input_data_path = 'data/combined_main.csv',\n",
    "        save_path = 'data/clean_data.csv',\n",
    "\n",
    "        # Set outlier criteria\n",
    "        av_crit = 100,   # allocation variance critical value\n",
    "        rb_crit = 2 ,    # response bias critical value\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Calculate heuristics\n",
    "|Heuristic|Description ($t_i$ = trial number $i$; $w$ = window size)|\n",
    "|:-------:|:--------------------------------------------------------|\n",
    "| **PC**  | overall competence ($t_0$ to $t_i$)                     |\n",
    "| **rPC** | recent competence ($t_{i-w}$ to $t_i$)                  |\n",
    "| **rLP** | recent learning progress ($t_{i-w}$ to $t_i$)           |\n",
    "| **SC**  | self-challenge                                          |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-25T22:22:55.382003Z",
     "start_time": "2020-10-25T22:20:56.021554Z"
    },
    "hidden": true,
    "run_control": {
     "marked": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Define a function for computing recent LP\n",
    "def rlp_func(x, subwindow_1, subwindow_2, abs_lp=True):\n",
    "    diff = np.mean(x[:subwindow_1]) - np.mean(x[-subwindow_2:])\n",
    "    return np.abs(diff) if abs_lp else diff\n",
    "\n",
    "\n",
    "def make_heuristics_dataset(input_data_path, save_path, **kwargs):\n",
    "    # Read clean data and drop unused data\n",
    "    df = pd.read_csv(input_data_path, index_col=None).set_index(['sid','activity'])\n",
    "    df = df.loc[:, 'group,stage,trial,correct'.split(',')]\n",
    "    df = df.loc[df.trial <= 60+250]\n",
    "#     df = df.sort_index()\n",
    "\n",
    "    # Add new columns\n",
    "    activities = 'A1,A2,A3,A4'.split(',')\n",
    "    for heuristic in ['pc','rpc','rlp']:\n",
    "        for a in activities:\n",
    "            df['{}{}'.format(heuristic, a[1])] = np.nan\n",
    "    df['sc'] = np.nan\n",
    "\n",
    "    # Calculate dynamic performance heuristics for each subject\n",
    "    act_codes = {'A1':1, 'A2':2, 'A3':3, 'A4':4}\n",
    "    for i, sdf in tqdm(df.groupby('sid'), desc='Progress: '):\n",
    "        for a in activities:\n",
    "            x = sdf.loc[(i, a), 'correct'].astype(int)\n",
    "\n",
    "            # Overall competence (pc)\n",
    "            pc = np.cumsum(x) / np.arange(1, x.size+1)\n",
    "            df.loc[(i, a), 'pc{}'.format(a[1])] = pc\n",
    "\n",
    "            # Recent competence (rpc)\n",
    "            rpc = x.rolling(min_periods=kwargs['window_size'], window=kwargs['window_size']).mean()\n",
    "            df.loc[(i, a), 'rpc{}'.format(a[1])] = rpc\n",
    "\n",
    "            # Recent learning progress (rlp)\n",
    "            rlp = x.rolling(min_periods=kwargs['window_size'], window=kwargs['window_size']).apply(\n",
    "                rlp_func, args=(kwargs['subwindow_size_1'], kwargs['subwindow_size_2']), raw=False\n",
    "            )\n",
    "            df.loc[(i, a), 'rlp{}'.format(a[1])] = rlp\n",
    "        \n",
    "        df.loc[(i, slice(None)), :] = df.loc[(i, slice(None)), :].fillna(method='ffill', axis=0)\n",
    "\n",
    "        # Self-challenge (sc)\n",
    "        rpc_max = df.loc[(i, slice(None)), 'rpc1':'rpc4'].max(axis=1).rolling(min_periods=1, window=250).max()\n",
    "        rpc_min = df.loc[(i, slice(None)), 'rpc1':'rpc4'].min(axis=1).rolling(min_periods=1, window=250).min()\n",
    "        act_inds = np.array([act_codes[a] for a in sdf.index.get_level_values(1).tolist()]) - 1\n",
    "        current_rpc = df.loc[(i, slice(None)), 'rpc1':'rpc4'].values[np.arange(60+250), act_inds]\n",
    "        sc = 1 - (current_rpc-rpc_min)/(rpc_max-rpc_min)\n",
    "        df.loc[(i, slice(None)), 'sc'] = sc\n",
    "\n",
    "    df = df.reset_index().sort_values(by=['sid', 'trial'])\n",
    "    df.loc[df.stage=='train', 'sc'] = np.nan    # make sure SC is NaN during training\n",
    "    display(df.loc[(df.sid==0)&(df.trial>=1)&(df.trial<70), :])\n",
    "    \n",
    "    # Save data\n",
    "    if save_path:\n",
    "        df.reset_index().to_csv(save_path, index=False)\n",
    "    \n",
    "    \n",
    "if 1:\n",
    "    make_heuristics_dataset(\n",
    "        input_data_path = 'data/clean_data.csv',\n",
    "        save_path = 'heuristics_data.csv',\n",
    "        window_size = 15,\n",
    "        subwindow_size_1 = 10,\n",
    "        subwindow_size_2 = 6,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-25T19:09:57.982363Z",
     "start_time": "2020-10-25T19:09:57.697087Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import python_scripts.utils.loc_utils as lut\n",
    "df = lut.unpickle('data/lpreds_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-25T19:10:03.782169Z",
     "start_time": "2020-10-25T19:10:03.756136Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
