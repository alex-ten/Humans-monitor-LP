{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T10:34:09.670562Z",
     "start_time": "2020-11-16T10:34:09.658864Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import path\n",
    "from IPython.display import display\n",
    "from tqdm.notebook import tqdm\n",
    "from python_scripts.utils import loc_utils as lut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Combine raw data files\n",
    "Concatenate raw data and codify participant IDs into a more readable form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T13:41:32.622570Z",
     "start_time": "2020-11-16T13:41:30.554904Z"
    },
    "code_folding": [
     0
    ],
    "hidden": true,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "def combine_main_raw(input_data_paths, save_path):\n",
    "    # Open main files and combine them\n",
    "    df = pd.concat(\n",
    "        [pd.read_csv(p) for p in input_data_paths]\n",
    "    )\n",
    "\n",
    "    # Codify subject IDs\n",
    "    df.loc[:, 'sid'] = df.sid.astype('category').cat.codes\n",
    "\n",
    "    # Save combined data\n",
    "    print('saving to {}'.format(path.abspath(save_path)))\n",
    "    df.to_csv(path.join(save_path), index=False)\n",
    "    \n",
    "    \n",
    "combine_main_raw(\n",
    "    input_data_paths = ('data/raw/ig_main.csv', 'data/raw/eg_main.csv'),\n",
    "    save_path = 'data/combined_main.csv'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-25T14:17:09.510337Z",
     "start_time": "2020-10-25T14:17:09.505646Z"
    },
    "heading_collapsed": true
   },
   "source": [
    "# Exclude outliers\n",
    "Exclude outliers based on allocation bias and response bias. Report number of exclusions in each group based on allocation bias, then exclude from remaining data according response bias and report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T13:42:19.622820Z",
     "start_time": "2020-11-16T13:42:12.703595Z"
    },
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def make_clean_dataset(input_data_path, save_path, **kwargs):\n",
    "    # Define a response bias function\n",
    "    def rbf(x):\n",
    "        _, response_counts = np.unique(x.response, return_counts=True)\n",
    "        return np.max(response_counts) / np.sum(response_counts)\n",
    "\n",
    "\n",
    "    # Open combined data file\n",
    "    df = pd.read_csv(input_data_path, index_col=None).set_index('sid')\n",
    "\n",
    "    # Initialize columns to record values of interest\n",
    "    df['alloc_bias'], df['resp_bias'] = 0, 0\n",
    "\n",
    "    # Calculate values of interest\n",
    "    activities = ('A1', 'A2', 'A3', 'A4')\n",
    "    for sid, sdf in tqdm(df.groupby(by='sid'), desc='Progress: '):\n",
    "        # Allocation variance\n",
    "        counts = [sum(sdf.activity == i) for i in activities]\n",
    "        allocation_variance = np.std(counts)\n",
    "        df.loc[sid, 'alloc_bias'] = allocation_variance\n",
    "\n",
    "        # Response bias\n",
    "        response_bias = sdf.groupby('family').apply(rbf).mean()\n",
    "        df.loc[sid, 'resp_bias'] = response_bias\n",
    "\n",
    "    # Detect high allocation variance and response bias\n",
    "    df_ = df.reset_index().groupby('sid').head(1).reset_index()\n",
    "    df_['high_ab'] = df_.alloc_bias >= kwargs['ab_crit']\n",
    "    df_['high_rb'] = np.logical_and(df_.resp_bias > df_.resp_bias.mean() + kwargs['rb_crit'] * df_.resp_bias.std(), ~df_.high_ab)\n",
    "\n",
    "    display(df_.groupby(by='group')[['high_ab', 'high_rb']].sum().astype(int))\n",
    "    print('Found {} outliers'.format(np.logical_or(df_.high_ab, df_.high_rb).sum()))\n",
    "\n",
    "    # Exclude outliers\n",
    "    outlier = df_.loc[df_.high_ab | df_.high_rb, 'sid']\n",
    "    df = df.loc[~df.index.isin(outlier), :]\n",
    "    display(df.reset_index().groupby(by='group')['sid'].nunique())\n",
    "\n",
    "    # Save data\n",
    "    if save_path:\n",
    "        print('saving to {}'.format(path.abspath(save_path)))\n",
    "        df.reset_index().to_csv(save_path, index=False)\n",
    "    \n",
    "\n",
    "make_clean_dataset(\n",
    "    input_data_path = 'data/combined_main.csv',\n",
    "    save_path = 'data/clean_data.csv',\n",
    "\n",
    "    # Set outlier criteria\n",
    "    ab_crit = 100,   # allocation variance critical value\n",
    "    rb_crit = 2 ,    # response bias critical value\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Calculate heuristics\n",
    "|Heuristic|Description ($t_i$ = trial number $i$; $w$ = window size)|\n",
    "|:-------:|:--------------------------------------------------------|\n",
    "| **PC**  | overall competence ($t_0$ to $t_i$)                     |\n",
    "| **rPC** | recent competence ($t_{i-w}$ to $t_i$)                  |\n",
    "| **rLP** | recent learning progress ($t_{i-w}$ to $t_i$)           |\n",
    "| **SC**  | self-challenge                                          |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T13:25:23.315528Z",
     "start_time": "2020-11-16T13:25:22.215556Z"
    },
    "code_folding": [
     0
    ],
    "hidden": true,
    "run_control": {
     "marked": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def rlp_func(x, subwindow_1, subwindow_2, abs_lp=True):\n",
    "    '''Computing recent LP in x'''\n",
    "    diff = np.mean(x[:subwindow_1]) - np.mean(x[-subwindow_2:])\n",
    "    return np.abs(diff) if abs_lp else diff\n",
    "\n",
    "\n",
    "def make_heuristics_dataset(input_data_path, save_path, **kwargs):\n",
    "    # Read clean data and drop unused data\n",
    "    df = pd.read_csv(input_data_path, index_col=None).set_index(['sid','activity'])\n",
    "    df = df.loc[:, 'group,stage,trial,correct'.split(',')]\n",
    "    df = df.loc[df.trial <= 60+250]\n",
    "\n",
    "    # Add new columns\n",
    "    activities = 'A1,A2,A3,A4'.split(',')\n",
    "    for heuristic in ['pc','rpc','rlp']:\n",
    "        for a in activities:\n",
    "            df['{}{}'.format(heuristic, a[1])] = np.nan\n",
    "    df['sc'] = np.nan\n",
    "    df = df.loc[(0, slice(None)), :]\n",
    "    # Calculate dynamic performance heuristics for each subject\n",
    "    act_codes = {'A1':1, 'A2':2, 'A3':3, 'A4':4}\n",
    "    for i, sdf in tqdm(df.groupby('sid'), desc='Progress: '):\n",
    "        for a in activities:\n",
    "            x = sdf.loc[(i, a), 'correct'].astype(int)\n",
    "\n",
    "            # Overall competence (pc)\n",
    "            pc = np.cumsum(x) / np.arange(1, x.size+1)\n",
    "            df.loc[(i, a), 'pc{}'.format(a[1])] = pc\n",
    "\n",
    "            # Recent competence (rpc)\n",
    "            rpc = x.rolling(min_periods=kwargs['window_size'], window=kwargs['window_size']).mean()\n",
    "            df.loc[(i, a), 'rpc{}'.format(a[1])] = rpc\n",
    "\n",
    "            # Recent learning progress (rlp)\n",
    "            rlp = x.rolling(min_periods=kwargs['window_size'], window=kwargs['window_size']).apply(\n",
    "                rlp_func, args=(kwargs['subwindow_size_1'], kwargs['subwindow_size_2']), raw=False\n",
    "            )\n",
    "            df.loc[(i, a), 'rlp{}'.format(a[1])] = rlp\n",
    "        \n",
    "        df.loc[(i, slice(None)), :] = df.loc[(i, slice(None)), :].fillna(method='ffill', axis=0)\n",
    "\n",
    "        # Self-challenge (sc)\n",
    "        rpc_max = df.loc[(i, slice(None)), 'rpc1':'rpc4'].max(axis=1).rolling(min_periods=1, window=250).max()\n",
    "        rpc_min = df.loc[(i, slice(None)), 'rpc1':'rpc4'].min(axis=1).rolling(min_periods=1, window=250).min()\n",
    "        act_inds = np.array([act_codes[a] for a in sdf.index.get_level_values(1).tolist()]) - 1\n",
    "        current_rpc = df.loc[(i, slice(None)), 'rpc1':'rpc4'].values[np.arange(60+250), act_inds]\n",
    "        sc = 1 - (current_rpc-rpc_min)/(rpc_max-rpc_min)\n",
    "        df.loc[(i, slice(None)), 'sc'] = sc\n",
    "\n",
    "    df = df.reset_index().sort_values(by=['sid', 'trial'])\n",
    "    df.loc[df.stage=='train', 'sc'] = np.nan    # SC is not defined in familizarization stage\n",
    "    display(df.loc[(df.sid == 0) & (df.trial >= 1) & (df.trial < 70), :])    # Display data excerpt\n",
    "    \n",
    "    # Save data\n",
    "    if save_path:\n",
    "        print('saving to {}'.format(path.abspath(save_path)))\n",
    "        df.to_csv(save_path, index=False)\n",
    "    \n",
    "    \n",
    "make_heuristics_dataset(\n",
    "    input_data_path = 'data/clean_data.csv',\n",
    "    save_path = 'data/heuristics_data.csv',\n",
    "    window_size = 15,\n",
    "    subwindow_size_1 = 10,\n",
    "    subwindow_size_2 = 6,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# NAM designation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T13:44:17.440941Z",
     "start_time": "2020-11-16T13:44:16.465064Z"
    },
    "code_folding": [
     0,
     8
    ],
    "hidden": true,
    "run_control": {
     "marked": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_mps(df, **kwargs):\n",
    "    '''Find mastery points'''\n",
    "    arr = df.values\n",
    "    mask = (arr != 0)\n",
    "    arr = np.where(mask.any(axis=0), mask.argmax(axis=0), kwargs['invalid_val'])\n",
    "    return pd.Series(arr, dtype=kwargs['dtype'])\n",
    "\n",
    "\n",
    "def make_nam_dataset(input_data_path, save_path, **kwargs):\n",
    "    # Load data\n",
    "    df = pd.read_csv(input_data_path, index_col='sid')\n",
    "\n",
    "    # Select free-play trials\n",
    "    df = df.loc[(df.trial <= 60+250) & (df.trial >= 60)]\n",
    "    df.loc[:, 'trial'] -= 60\n",
    "\n",
    "    # Evaluate each trial's recent PC to True if mastery criterion was reached\n",
    "    mastered = df.reset_index().set_index(['sid','trial']).loc[:, 'rpc1':'rpc3'] >= kwargs['crit']\n",
    "    \n",
    "    # For each subject, find mastery points and NAM\n",
    "    by_sid = mastered.groupby('sid')\n",
    "    mastery_points = by_sid.apply(get_mps, invalid_val=250, dtype='int')\n",
    "    mastery_points.rename(columns={0:'mp1', 1:'mp2', 2:'mp3'}, inplace=True)\n",
    "    nam = by_sid.any().sum(axis=1).to_frame(name='nam')\n",
    "\n",
    "    # Display output dataset excerpt\n",
    "    nam_df = nam.merge(mastery_points, on='sid').reset_index()\n",
    "    display(nam_df.head(10))\n",
    "    \n",
    "    # Save data\n",
    "    if save_path:\n",
    "        print('saving to {}'.format(path.abspath(save_path)))\n",
    "        nam_df.to_csv(save_path, index=False)    \n",
    "\n",
    "\n",
    "make_nam_dataset(\n",
    "    input_data_path = 'data/heuristics_data.csv', \n",
    "    save_path = 'data/nam_data.csv',\n",
    "    crit = 13/15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Learning dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T14:02:15.935101Z",
     "start_time": "2020-11-16T14:02:07.961545Z"
    },
    "code_folding": [
     0
    ],
    "hidden": true,
    "run_control": {
     "marked": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def make_learning_dataset(input_data_path, save_path, **kwargs):    \n",
    "    # Load data\n",
    "    df = pd.read_csv('data/heuristics_data.csv', index_col='sid')\n",
    "    \n",
    "    # Combine with NAM dataset\n",
    "    df = df.merge(pd.read_csv('data/nam_data.csv', index_col='sid'), on='sid')\n",
    "    \n",
    "    # Encode activity choices as one-hot vectors\n",
    "    df = pd.concat([df, pd.get_dummies(df.activity, prefix='ch')], axis = 1)\n",
    "    \n",
    "    # Annotate switch trials\n",
    "    df['switch'] = 0\n",
    "    choices = df.activity.values\n",
    "    switches = df.switch.values.copy() \n",
    "    switches[1:] = choices[:-1] != choices[1:]\n",
    "    df.loc[:, 'switch'] = switches\n",
    "    df.loc[df.stage=='train', 'switch'] = 0  # changing activity during forced stage is not switching\n",
    "    df.loc[df.trial==61, 'switch'] = 0       # choosing activity for the first time is not switching\n",
    "    \n",
    "    # Select free-play trials\n",
    "    df = df.loc[(df.trial <= 60+250) & (df.trial > 60)]\n",
    "    df.loc[:, 'trial'] -= 61\n",
    "    \n",
    "    # For each subject, compute learning stats from free play stage\n",
    "    df.reset_index(inplace=True)\n",
    "    outdf = []\n",
    "    for i, sdf in tqdm(df.groupby('sid'), desc='Progress: '):\n",
    "        _sdf = sdf.set_index('trial') # index subject data by trial\n",
    "    \n",
    "        # Get subject information (group, nam, mps) as a pandas Series\n",
    "        profile = _sdf.head(1)[['group', 'nam', 'mp1', 'mp2', 'mp3']].iloc[0]\n",
    "\n",
    "        # Get intervals between consecutive mastery points\n",
    "        mps = profile['mp1':'mp3'].values\n",
    "        sorted_lep_bounds = np.sort(np.unique([0] + mps.tolist() + [250]))  \n",
    "        lep_intervals = pd.IntervalIndex.from_arrays(sorted_lep_bounds[:-1], sorted_lep_bounds[1:], closed='right')\n",
    "\n",
    "        # Get intervals between consecutive swiches\n",
    "        switch_trials = _sdf.switch.values.nonzero()[0].tolist() + [250]\n",
    "        if switch_trials[0] != 1: switch_trials.insert(0,1)\n",
    "        streaks = pd.IntervalIndex.from_arrays(switch_trials[:-1], switch_trials[1:], closed='right')\n",
    "\n",
    "        # Calculate self-challenge (SC) summaries\n",
    "        sc = _sdf.sc\n",
    "        sc_flat = np.mean(sc)\n",
    "        sc_lep = sc.groupby(pd.cut(_sdf.index.astype(int), lep_intervals)).mean().mean()\n",
    "        sc_streaks = sc.groupby(pd.cut(_sdf.index.astype(int), streaks)).mean().mean()    \n",
    "\n",
    "        # Calculate weighted initial (dwipc) and final (dwfpc) performances\n",
    "        dwipc = (_sdf.loc[0, 'rpc1':'rpc3'].values * kwargs['difficulty_weights']).sum()\n",
    "        dwfpc = (_sdf.loc[249, 'rpc1':'rpc3'].values * kwargs['difficulty_weights']).sum()\n",
    "\n",
    "        # Get profile info and see if subject mastered activities in order of difficulty\n",
    "        sid = i\n",
    "        group = profile['group']\n",
    "        nam = profile['nam']\n",
    "        progressive = (np.diff(np.array([1,2,3])[np.argsort(mps)]) == 1).all()\n",
    "        \n",
    "        # Store subject's learning stats\n",
    "        outdf.append(\n",
    "            pd.Series(\n",
    "                data = [sid,group,nam,progressive,dwipc,dwfpc,sc_flat,sc_lep,sc_streaks], \n",
    "                index='sid,group,nam,progressive,dwipc,dwfpc,sc_flat,sc_lep,sc_streaks'.split(',')\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    outdf = pd.DataFrame(outdf).sort_values(by=['group','sid'])\n",
    "    display(outdf.head())\n",
    "    \n",
    "    # Save data\n",
    "    if save_path:\n",
    "        print('saving to {}'.format(path.abspath(save_path)))\n",
    "        outdf.to_csv(save_path, index=False)\n",
    "    \n",
    "\n",
    "make_learning_dataset(\n",
    "    input_data_path = 'data/ntm_data_freeplay.pkl',\n",
    "    save_path = 'data/learning_data.csv',\n",
    "    difficulty_weights = np.array([1,2,3])/6\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
