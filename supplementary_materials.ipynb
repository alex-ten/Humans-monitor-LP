{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T16:16:15.790901Z",
     "start_time": "2021-02-16T16:16:13.105530Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec, lines, legend_handler\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as scs\n",
    "from scipy import ndimage\n",
    "from statsmodels.formula.api import ols\n",
    "from os import path\n",
    "from io import StringIO\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from matplotlib.collections import LineCollection\n",
    "from matplotlib.patches import Patch\n",
    "from matplotlib.lines import Line2D\n",
    "from cycler import cycler\n",
    "import warnings\n",
    "import itertools\n",
    "\n",
    "from python_scripts.utils import loc_utils as lut\n",
    "from python_scripts.utils import vis_utils as vut\n",
    "from python_scripts.utils import model_utils as mut\n",
    "from python_scripts.utils.vis_utils import gcolors, glabels, fullglabels, gmarkers, colors, ncolors, tlabels\n",
    "from python_scripts.utils.model_utils import *\n",
    "\n",
    "plt.style.use('python_scripts/my.mplstyle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Visualize outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def make_clean_dataset(input_data_path, save_path, **kwargs):\n",
    "    # Define a response bias function\n",
    "    def rbf(x):\n",
    "        _, response_counts = np.unique(x.response, return_counts=True)\n",
    "        return np.max(response_counts) / np.sum(response_counts)\n",
    "\n",
    "\n",
    "    # Open combined data file\n",
    "    df = pd.read_csv(input_data_path, index_col=None).set_index('sid')\n",
    "\n",
    "    # Initialize columns to record values of interest\n",
    "    df['alloc_bias'], df['resp_bias'] = 0, 0\n",
    "\n",
    "    # Calculate values of interest\n",
    "    activities = ('A1', 'A2', 'A3', 'A4')\n",
    "    for sid, sdf in tqdm(df.groupby(by='sid'), desc='Progress: '):\n",
    "        # Allocation variance\n",
    "        counts = [sum(sdf.activity == i) for i in activities]\n",
    "        allocation_variance = np.std(counts)\n",
    "        df.loc[sid, 'alloc_bias'] = allocation_variance\n",
    "\n",
    "        # Response bias\n",
    "        response_bias = sdf.groupby('family').apply(rbf).mean()\n",
    "        df.loc[sid, 'resp_bias'] = response_bias\n",
    "\n",
    "    # Detect high allocation variance and response bias\n",
    "    df_ = df.reset_index().groupby('sid').head(1).reset_index()\n",
    "    df_['high_ab'] = df_.alloc_bias >= kwargs['ab_crit']\n",
    "    df_['high_rb'] = np.logical_and(df_.resp_bias > df_.resp_bias.mean() + kwargs['rb_crit'] * df_.resp_bias.std(), ~df_.high_ab)\n",
    "\n",
    "    display(df_.groupby(by='group')[['high_ab', 'high_rb']].sum().astype(int))\n",
    "    print('Found {} outliers'.format(np.logical_or(df_.high_ab, df_.high_rb).sum()))\n",
    "\n",
    "    # Exclude outliers\n",
    "    outlier = df_.loc[df_.high_ab | df_.high_rb, 'sid']\n",
    "    df = df.loc[~df.index.isin(outlier), :] if exclude else df\n",
    "    display(df.reset_index().groupby(by='group')['sid'].nunique())\n",
    "\n",
    "    # Save data\n",
    "    if save_path:\n",
    "        print('saving to {}'.format(path.abspath(save_path)))\n",
    "        df.reset_index().to_csv(save_path, index=False)\n",
    "    \n",
    "\n",
    "exclude = False\n",
    "save_path = 'data/clean_data.csv' if exclude else 'data/unclean_data.csv'\n",
    "\n",
    "make_clean_dataset(\n",
    "    input_data_path = 'data/combined_main.csv',\n",
    "    save_path = save_path,\n",
    "\n",
    "    # Set outlier criteria\n",
    "    ab_crit = 100,   # allocation variance critical value\n",
    "    rb_crit = 2 ,    # response bias critical value\n",
    "    \n",
    "    # Retain or not\n",
    "    exclude = exclude\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Activity choices in different NAM groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T16:11:23.870330Z",
     "start_time": "2021-02-16T16:11:23.163497Z"
    },
    "code_folding": [
     0
    ],
    "hidden": true,
    "run_control": {
     "marked": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def make_fig(data_path, nam_data_path, figname, save_to, save_as=None):\n",
    "    # Load data\n",
    "    df = pd.read_csv(data_path).filter(items=['sid','group','trial','activity'])\n",
    "    \n",
    "    # Select only required free-play trials (N = 250)\n",
    "    df = df.loc[df.trial.le(60+250) & df.trial.gt(60), :]\n",
    "    nam_df = pd.read_csv(nam_data_path).filter(items=['sid','nam']).set_index('sid')\n",
    "    df = df.dropna().drop(columns='trial')\n",
    "    df = df.merge(nam_df, on='sid')\n",
    "    df = df.loc[df.nam.gt(0), :]\n",
    "    \n",
    "    # Count trials per activity for each subject\n",
    "    counts = df.groupby(['group', 'nam', 'sid']).activity.value_counts().to_frame('counts')\n",
    "    counts = 100*counts / counts.groupby(['group', 'nam', 'sid']).transform('sum')\n",
    "    counts_stats = counts.groupby(['group','nam','activity']).agg(['mean', 'sem'])\n",
    "    counts_stats.columns = counts_stats.columns.droplevel(0)\n",
    "    display(counts_stats)\n",
    "\n",
    "    fig = plt.figure(figname, figsize=[8, 3])\n",
    "    for nam in [1,2,3]:\n",
    "        ax = vut.pretty(fig.add_subplot(1,3,nam), 'y')\n",
    "        ax.axhline(25, ls='--', color='k', alpha=.8)\n",
    "        x = np.array([1, 2, 3, 4])\n",
    "        for i, group in enumerate([1, 0]):\n",
    "            x_ = x+[-.1, .1][group]\n",
    "            y = counts_stats.loc[(group, nam, slice(None)), 'mean']\n",
    "            yerr = counts_stats.loc[(group, nam, slice(None)), 'sem']\n",
    "            ax.errorbar(x_, y, yerr=yerr, color=gcolors[group], marker=gmarkers[group],\n",
    "                        capsize=5, markersize=8, lw=2, label=fullglabels[group])\n",
    "        ax.set_ylim(10, 57)\n",
    "        ax.set_xticks(x)\n",
    "        ax.set_xticklabels(['A1', 'A2', 'A3', 'A4'], fontsize=12, fontweight='bold')\n",
    "        for xt, c in zip(ax.get_xticklabels(), colors):\n",
    "            xt.set_color(c)\n",
    "        \n",
    "        ax.set_title('NAM {}'.format(nam), fontsize=12)\n",
    "        if nam == 1: \n",
    "            ax.set_ylabel('Trials per activity\\n(%; Mean and SEM)', fontsize=12)\n",
    "        if nam == 2: \n",
    "            ax.set_xlabel('Learning activity'.format(nam), fontsize=12)\n",
    "        \n",
    "    leg = ax.legend(fontsize=12)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    if save_as:\n",
    "        vut.save_it(fig, save_to, figname, save_as=save_as, compress=False)\n",
    "\n",
    "\n",
    "make_fig(\n",
    "    data_path = 'data/clean_data.csv',\n",
    "    nam_data_path = 'data/nam_data.csv',\n",
    "    figname = 'choices_by_nam',\n",
    "    save_to = 'figures',\n",
    "    save_as = '' # File format (png, jpeg, svg, ...)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Proportion of correct responses over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T16:12:23.525249Z",
     "start_time": "2021-02-16T16:12:23.008741Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def make_bottom_fig(data_path, figname, save_to, save_as=None):\n",
    "    # Load data, select columns\n",
    "    df = pd.read_csv(data_path)[['sid','group','trial','correct']]\n",
    "    \n",
    "    # Select free-play trials\n",
    "    df = df.loc[(df.trial <= 60+250) & (df.trial > 60)]\n",
    "    df.loc[:, 'trial'] -= 60\n",
    "    \n",
    "    # Calculate percentage of subjects who guessed correctly for each trial in each group\n",
    "    df = df.groupby(['group', 'trial'])[['correct']].mean()\n",
    "    df.loc[:, 'correct'] = df.correct * 100\n",
    "    \n",
    "    # Fit linear regression (set EG for contrast reference)\n",
    "    lm = ols('correct ~ trial*C(group,Treatment(reference=1))', data=df.reset_index()).fit()\n",
    "    params = lm.params\n",
    "    display(lm.summary())\n",
    "\n",
    "    # Make figure\n",
    "    fig = plt.figure(figname, figsize=[5, 3])\n",
    "    ax = vut.pretty(fig.add_subplot(111))\n",
    "\n",
    "    for grp in [0, 1]:\n",
    "        # Display raw percentages\n",
    "        x = np.arange(1, 251)\n",
    "        y = df.loc[(grp, slice(None)), :].values.squeeze()\n",
    "        ax.plot(x, y, color=gcolors[grp], ls='', alpha=.3, marker='.')\n",
    "        \n",
    "        # Display model predictions \n",
    "        x_ = np.array([1, 251])\n",
    "        y_ = lm.predict({'group': (grp, grp), 'trial': x_})\n",
    "        ax.plot(x_, y_, color=gcolors[grp], lw=2, alpha=.9, label=fullglabels[grp])\n",
    "        \n",
    "        # Print fitted line equations\n",
    "        intercept = params[0] + params[1] * grp\n",
    "        slope = params[2] + params[3] * grp\n",
    "        pos = int(slope > 0)\n",
    "        txt = 'Y = {:.3f} {} {:.3f}*X'.format(intercept, '-+'[pos], np.abs(slope))\n",
    "        print('group {}: {}'.format(grp, txt))\n",
    "\n",
    "    ax.set_xlabel('Trial', fontsize=14)\n",
    "    ax.set_ylabel('% correct', fontsize=14)\n",
    "\n",
    "    leg = ax.legend(fontsize=14, ncol=2)\n",
    "    vut.color_legend(leg)\n",
    "\n",
    "    ax.set_ylim(55, 85)\n",
    "    ax.set_xlim(1, 250)\n",
    "    fig.tight_layout()\n",
    "\n",
    "    if save_as:\n",
    "        vut.save_it(fig, save_to, figname, save_as=save_as, compress=False)\n",
    "        \n",
    "\n",
    "make_bottom_fig(\n",
    "    data_path='data/clean_data.csv',\n",
    "    figname='figure2b_bottom',\n",
    "    save_to='figures',\n",
    "    save_as='' # File format (png, jpeg, svg, ...)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Self-challenge index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Relationship with *flat* final performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-21T21:36:10.023790Z",
     "start_time": "2021-01-21T21:36:09.078139Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def make_fig(data_path, figname, save_to, save_as=''):\n",
    "    df = pd.read_csv(data_path)\n",
    "    df = df.loc[df.nam > 0, :]\n",
    "\n",
    "    propS = np.sum(df.group == 1) / df.shape[0]\n",
    "\n",
    "    fig = plt.figure(figname, figsize=[7, 7])\n",
    "    gs = gridspec.GridSpec(2, 2)\n",
    "\n",
    "    # Make figure (scatter plot and histograms)\n",
    "    ghost_top = fig.add_subplot(gs[0, 0])\n",
    "    ghost_top.set_ylabel('Relative frequency', fontsize=14, labelpad=30)\n",
    "    ghost_top.tick_params(left=False, labelleft=False, bottom=False, labelbottom=False)\n",
    "    for spine in ghost_top.spines.values(): spine.set_visible(False)\n",
    "\n",
    "    ax_top1 = vut.pretty(inset_axes(ghost_top, width='100%', height='30%', loc=9, borderpad=0))\n",
    "    ax_top2 = vut.pretty(inset_axes(ghost_top, width='100%', height='30%', loc=10, borderpad=0))\n",
    "    ax_top3 = vut.pretty(inset_axes(ghost_top, width='100%', height='30%', loc=8, borderpad=0))\n",
    "\n",
    "    ghost_right = fig.add_subplot(gs[1, 1])\n",
    "    ghost_right.set_xlabel('Relative frequency', fontsize=14, labelpad=30)\n",
    "    ghost_right.tick_params(left=False, labelleft=False, bottom=False, labelbottom=False)\n",
    "    for spine in ghost_right.spines.values(): spine.set_visible(False)\n",
    "    ax_right1 = vut.pretty(inset_axes(ghost_right, width='30%', height='100%', loc=6, borderpad=0))\n",
    "    ax_right2 = vut.pretty(inset_axes(ghost_right, width='30%', height='100%', loc=10, borderpad=0))\n",
    "    ax_right3 = vut.pretty(inset_axes(ghost_right, width='30%', height='100%', loc=7, borderpad=0))\n",
    "\n",
    "    ax_scat = vut.pretty(fig.add_subplot(gs[1, 0]))\n",
    "\n",
    "    bins = np.arange(0, 1.02, .1)\n",
    "    labels = {'nam': ['NAM ' + str(i) for i in (0, 1, 2, 3)], 'group': fullglabels}\n",
    "    axes_by_nam = {\n",
    "        'top': {\n",
    "            3: ax_top1,\n",
    "            2: ax_top2,\n",
    "            1: ax_top3},\n",
    "        'right': {\n",
    "            1: ax_right1,\n",
    "            2: ax_right2,\n",
    "            3: ax_right3}}\n",
    "    for nam in [1, 2, 3]:\n",
    "        axes_by_nam['top'][nam].set_xlim(.0, .8)\n",
    "        axes_by_nam['top'][nam].set_ylim(0., .4)\n",
    "        axes_by_nam['right'][nam].set_xlim(0., .45)\n",
    "        axes_by_nam['right'][nam].set_ylim(0.38, 1.)\n",
    "        for group in [0, 1]:\n",
    "            x = df.loc[(df.nam == nam) & (df.group == group), 'sc_lep']\n",
    "            y = df.loc[(df.nam == nam) & (df.group == group), 'fpc']\n",
    "            ax_scat.scatter(x, y, s=30, alpha=.7,\n",
    "                            facecolors=ncolors[nam - 1] if group else 'w',\n",
    "                            edgecolors=ncolors[nam - 1])\n",
    "\n",
    "            rf, _ = np.histogram(x, bins=bins, weights=np.ones_like(x) / x.size)\n",
    "            axes_by_nam['top'][nam].plot(bins[:-1], rf, c=ncolors[nam - 1], lw=2,\n",
    "                                         ls='-' if group else '--',\n",
    "                                         label='{} / NAM-{}'.format(glabels[group], nam))\n",
    "            axes_by_nam['top'][nam].tick_params(labelbottom=False)\n",
    "            axes_by_nam['top'][nam].text(.02, .9, 'NAM-{}'.format(nam), ha='left', va='top', fontsize=12,\n",
    "                                         color=ncolors[nam - 1], transform=axes_by_nam['top'][nam].transAxes)\n",
    "\n",
    "            rf, _ = np.histogram(y, bins=bins, weights=np.ones_like(x) / x.size)\n",
    "            axes_by_nam['right'][nam].plot(rf, bins[1:], c=ncolors[nam - 1], lw=2,\n",
    "                                           ls='-' if group else '--',\n",
    "                                           label='{} / NAM-{}'.format(glabels[group], nam))\n",
    "            axes_by_nam['right'][nam].tick_params(labelleft=False)\n",
    "            axes_by_nam['right'][nam].text(.95, .02, 'NAM-{}'.format(nam), ha='right', va='bottom', fontsize=12,\n",
    "                                           color=ncolors[nam - 1], transform=axes_by_nam['right'][nam].transAxes)\n",
    "\n",
    "    ax_scat.set_xlim(.0, .8)\n",
    "    ax_scat.set_ylim(0.38, 1.)\n",
    "    ax_scat.set_xlabel('Self-challenge (SC)', fontsize=14)\n",
    "    ax_scat.set_ylabel('Mean performance', fontsize=14)\n",
    "\n",
    "    # Edit legend\n",
    "    c = 'darkgray'\n",
    "    mark_ig = lines.Line2D([0], [0], ls='', marker='o', label=fullglabels[0], markerfacecolor='w', markeredgecolor=c)\n",
    "    line_ig = lines.Line2D([0], [0], color=c, lw=2, label=fullglabels[0], ls='--', dashes=(2, 1))\n",
    "\n",
    "    mark_eg = lines.Line2D([0], [0], color=c, ls='', marker='o', label=fullglabels[1])\n",
    "    line_eg = lines.Line2D([0], [0], color=c, lw=2, label=fullglabels[1])\n",
    "\n",
    "    ax_scat.legend(((line_ig, mark_ig), (line_eg, mark_eg)), fullglabels.values(),\n",
    "                   bbox_to_anchor=(.5, 1.1,),\n",
    "                   fontsize=12, ncol=3, loc='center',\n",
    "                   handler_map={tuple: legend_handler.HandlerTuple(ndivide=None)})\n",
    "\n",
    "    # Plot line of best fit for unstandardized data\n",
    "    qreg = ols('fpc ~ (ipc + {0} + np.power({0}, 2) + group)'.format('sc_lep'), data=df).fit()\n",
    "    x = np.linspace(df.loc[:, 'sc_lep'].min(), df.loc[:, 'sc_lep'].max(), 100)\n",
    "    y_hat = qreg.get_prediction({'sc_lep': x,\n",
    "                                 'ipc': np.full_like(x, df.dwipc.mean()),\n",
    "                                 'group': np.full_like(x, propS)\n",
    "                                 }).summary_frame()\n",
    "    display(y_hat.head())\n",
    "    c, alpha = 'k', .7\n",
    "    ax_scat.plot(x, y_hat['mean'], c=c, alpha=alpha)\n",
    "    ax_scat.plot(x, y_hat['mean_ci_lower'], c=c, lw=1, ls='--', alpha=alpha)\n",
    "    ax_scat.plot(x, y_hat['mean_ci_upper'], c=c, lw=1, ls='--', alpha=alpha)\n",
    "    \n",
    "    # Run quadratic regression of final performance\n",
    "    df.loc[:, 'sc_lep'] = scs.stats.zscore(df.loc[:, 'sc_lep']) # Standardize x before fitting the quadratic model\n",
    "    qreg = ols('dwfpc ~ dwipc + group + sc_lep + np.power(sc_lep, 2)', data=df).fit()\n",
    "    display(qreg.summary())\n",
    "    \n",
    "    # Run nonquadratic regression and compare AIC\n",
    "    nonqreg = ols('fpc ~ (ipc + sc_lep + group)', data=df).fit()\n",
    "    print('Delta AIC = {:.2f}'.format(qreg.aic - nonqreg.aic))\n",
    "\n",
    "    # Run model of average SC as a function of Group x NAM\n",
    "    lreg = ols('sc_lep ~ C(group) * C(nam)', data=df).fit()\n",
    "    display(lreg.summary())\n",
    "    \n",
    "    # Show group and subgroup counts\n",
    "    display(df.groupby(['group', 'nam'])['sid'].agg('count'))\n",
    "    \n",
    "    # Save figure\n",
    "    fig.tight_layout()\n",
    "    if save_as:\n",
    "        vut.save_it(fig, save_to, figname=figname, save_as=save_as, compress=False, dpi=100)\n",
    "\n",
    "\n",
    "make_fig(\n",
    "    data_path = 'data/learning_data.csv',\n",
    "    figname = 'sm_fig4',\n",
    "    save_to = 'figures',\n",
    "    save_as = '' # File format (png, jpeg, svg, ...)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Relationship with activity choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T16:12:55.264130Z",
     "start_time": "2021-02-16T16:12:51.976693Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def main(model_data_path, learning_data_path, figname, save_to, save_as=''):\n",
    "    # Load data\n",
    "    df = pd.read_csv(model_data_path, index_col='sid')\n",
    "    df = df.filter(items='trial,abst1,abst2,abst3,abst4'.split(',')).set_index('trial', append=True)\n",
    "    df = df.loc[(slice(None), 250), :]\n",
    "    df.index = df.index.droplevel(1)\n",
    "    df = df.rename(columns={'abst1':'A1','abst2':'A2','abst3':'A3','abst4':'A4'})\n",
    "    \n",
    "    df = df.merge(pd.read_csv(learning_data_path, index_col='sid').filter(items=['sc_flat']), on='sid')\n",
    "    display(df.head())\n",
    "    \n",
    "    fig = plt.figure(num=figname, figsize=[8, 8])\n",
    "    gs = GridSpec(4, 4)\n",
    "    \n",
    "    ghost = fig.add_subplot(111)\n",
    "    ghost.set_title('Correlations of activity preferences with average SC', pad=10)\n",
    "    ghost.set_ylabel('Average SC', fontsize=14, labelpad=35)\n",
    "    ghost.set_xlabel('Choice preference', fontsize=14, labelpad=30)\n",
    "    ghost.tick_params(left=False, labelleft=False, bottom=False, labelbottom=False)\n",
    "    for spine in ghost.spines.values(): \n",
    "        spine.set_visible(False)\n",
    "    \n",
    "    for i, act1 in enumerate(['A1','A2','A3','A4']):\n",
    "        for j, act2 in enumerate(['A1','A2','A3','A4']):\n",
    "            ax = vut.pretty(fig.add_subplot(gs[i, j]))\n",
    "#             ax.set_xlim(-250, 250)\n",
    "            ax.set_ylim(0, 1)\n",
    "            if i != 3:\n",
    "                ax.tick_params(labelbottom=False)\n",
    "            if j:\n",
    "                ax.tick_params(labelleft=False)\n",
    "            if i == j:\n",
    "                plt.axis('off')\n",
    "                continue\n",
    "            else:\n",
    "                x = df.loc[:, act1] - df.loc[:, act2]\n",
    "                y = df.loc[:, 'sc_flat']\n",
    "                sns.regplot(\n",
    "                    x=x, y=y, ax=ax, color='k',\n",
    "                    scatter_kws={'alpha': .3, 's': 3}\n",
    "                )\n",
    "                ax.set_ylabel('')\n",
    "                ax.text(0, .83, '{} - {}'.format(act1, act2), ha='center')\n",
    "        \n",
    "    if save_as:\n",
    "        vut.save_it(fig, save_to, figname=figname, save_as=save_as, compress=False, dpi=100)\n",
    "    \n",
    "\n",
    "main(\n",
    "    model_data_path = 'data/model_data.csv',\n",
    "    learning_data_path = 'data/learning_data.csv',\n",
    "    figname = 'response_fig3',\n",
    "    save_to = 'figures',\n",
    "    save_as = 'png' # File format (png, jpeg, svg, ...)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Learning and preference for A3 vs A1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T16:14:07.191629Z",
     "start_time": "2021-02-16T16:14:06.134650Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def make_fig(data_path, data_path2, figname, save_to, save_as=''):\n",
    "    df2 = pd.read_csv(data_path2, index_col='sid')\n",
    "    df2 = df2.filter(items='trial,abst1,abst2,abst3,abst4'.split(',')).set_index('trial', append=True)\n",
    "    df2 = df2.loc[(slice(None), 250), :]\n",
    "    df2.index = df2.index.droplevel(1)\n",
    "    df2 = df2.rename(columns={'abst1':'A1','abst2':'A2','abst3':'A3','abst4':'A4'})\n",
    "    display(df2.head())\n",
    "    \n",
    "    df = pd.read_csv(data_path).merge(df2, on='sid')\n",
    "    df = df.loc[df.nam > 0, :]\n",
    "    df['pref'] = df.A3\n",
    "\n",
    "    propS = np.sum(df.group == 1) / df.shape[0]\n",
    "\n",
    "    fig = plt.figure(figname, figsize=[4, 4])\n",
    "\n",
    "    ax_scat = vut.pretty(fig.add_subplot(111))\n",
    "\n",
    "    bins = np.arange(0, 1.02, .1)\n",
    "    labels = {'nam': ['NAM ' + str(i) for i in (0, 1, 2, 3)], 'group': fullglabels}\n",
    "    for nam in [1, 2, 3]:\n",
    "        for group in [0, 1]:\n",
    "            x = df.loc[(df.nam == nam) & (df.group == group), 'pref']\n",
    "            y = df.loc[(df.nam == nam) & (df.group == group), 'dwipc']\n",
    "            ax_scat.scatter(x, y, s=30, alpha=.7,\n",
    "                            facecolors=ncolors[nam - 1] if group else 'w',\n",
    "                            edgecolors=ncolors[nam - 1])\n",
    "\n",
    "#     ax_scat.set_xlim(-245, 200)\n",
    "    ax_scat.set_ylim(0.38, 1.)\n",
    "    ax_scat.set_xlim(0, 250)\n",
    "    ax_scat.set_xlabel('Selection of A4 vs. A1', fontsize=14)\n",
    "    ax_scat.set_ylabel('Mean performance', fontsize=14)\n",
    "\n",
    "    # Edit legend\n",
    "    c = 'darkgray'\n",
    "    mark_ig = lines.Line2D([0], [0], ls='', marker='o', label=fullglabels[0], markerfacecolor='w', markeredgecolor=c)\n",
    "    line_ig = lines.Line2D([0], [0], color=c, lw=2, label=fullglabels[0], ls='--', dashes=(2, 1))\n",
    "\n",
    "    mark_eg = lines.Line2D([0], [0], color=c, ls='', marker='o', label=fullglabels[1])\n",
    "    line_eg = lines.Line2D([0], [0], color=c, lw=2, label=fullglabels[1])\n",
    "\n",
    "    ax_scat.legend(((line_ig, mark_ig), (line_eg, mark_eg)), fullglabels.values(),\n",
    "                   bbox_to_anchor=(.5, 1.1,),\n",
    "                   fontsize=12, ncol=3, loc='center',\n",
    "                   handler_map={tuple: legend_handler.HandlerTuple(ndivide=None)})\n",
    "\n",
    "    \n",
    "    # Run quadratic regression of final performance\n",
    "    df.loc[:, 'pref'] = scs.stats.zscore(df.loc[:, 'pref']) # Standardize x before fitting the quadratic model\n",
    "    qreg = ols('pref ~ dwipc', data=df).fit()\n",
    "    display(qreg.summary())\n",
    "    \n",
    "    # Run nonquadratic regression and compare AIC\n",
    "    nonqreg = ols('dwfpc ~ (dwipc + pref + group)', data=df).fit()\n",
    "    display(nonqreg.summary())\n",
    "    print('Delta AIC = {:.2f}'.format(qreg.aic - nonqreg.aic))\n",
    "\n",
    "    \n",
    "    # Show group and subgroup counts\n",
    "    display(df.groupby(['group', 'nam'])['sid'].agg('count'))\n",
    "    \n",
    "    # Save figure\n",
    "    fig.tight_layout()\n",
    "    if save_as:\n",
    "        vut.save_it(fig, save_to, figname=figname, save_as=save_as, compress=False, dpi=100)\n",
    "\n",
    "\n",
    "make_fig(\n",
    "    data_path = 'data/learning_data.csv',\n",
    "    data_path2 = 'data/model_data.csv',\n",
    "    figname = 'response_fig4',\n",
    "    save_to = 'figures',\n",
    "    save_as = '' # File format (png, jpeg, svg, ...)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Self-reports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Average ratings by instruction and NAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T16:16:19.270059Z",
     "start_time": "2021-02-16T16:16:18.861297Z"
    },
    "code_folding": [
     0
    ],
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def make_fig(data_path, nam_data_path, item, norm, figname, save_to, save_as=None):\n",
    "    # Load data\n",
    "    df = pd.read_csv(data_path)\n",
    "    df = df.merge(pd.read_csv(nam_data_path).loc[:, ('sid', 'nam')], on='sid')\n",
    "    df = df.loc[df.item.eq(item) & df.nam.gt(0), :]\n",
    "    \n",
    "    if norm:\n",
    "        df.loc[:, 'rating'] = df.rating_norm\n",
    "        df.drop(columns='rating_norm', inplace=True)\n",
    "    \n",
    "    # Calculate average scores\n",
    "    df = df.groupby(['group','nam','activity'])[['rating']].agg(['mean', 'sem'])\n",
    "    df.columns = df.columns.droplevel(0)\n",
    "    display(df)\n",
    "    \n",
    "    # Plot results\n",
    "    fig = plt.figure(figname, figsize=[8, 3])\n",
    "    for nam in [1,2,3]:\n",
    "        ax = vut.pretty(fig.add_subplot(1, 3, nam), 'y')\n",
    "        x = np.array([1, 2, 3, 4])\n",
    "        for i, grp in enumerate([1, 0]):\n",
    "            x_ = x+[-.1, .1][grp]\n",
    "            y = df.loc[(grp, nam, slice(None)), 'mean']\n",
    "            yerr = df.loc[(grp, nam, slice(None)), 'sem']\n",
    "            ax.errorbar(x_, y, yerr=yerr, color=gcolors[grp], marker=gmarkers[grp],\n",
    "                        capsize=5, markersize=8, lw=2, label=fullglabels[grp])\n",
    "#         ax.set_ylim(4.2, 8.1)\n",
    "        ax.set_xticks(x)\n",
    "        ax.set_xticklabels(['A1', 'A2', 'A3', 'A4'], fontsize=12, fontweight='bold')\n",
    "        for xt, c in zip(ax.get_xticklabels(), colors):\n",
    "            xt.set_color(c)\n",
    "        \n",
    "        ax.set_title('NAM {}'.format(nam), fontsize=12)\n",
    "        if nam == 1: \n",
    "            ax.set_ylabel('Subjective interest\\n(Mean and SEM)', fontsize=12)\n",
    "        if nam == 2: \n",
    "            ax.set_xlabel('Learning activity'.format(nam), fontsize=12)\n",
    "        \n",
    "    leg = ax.legend(fontsize=12)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    if save_as:\n",
    "        vut.save_it(fig, save_to, figname, save_as=save_as, compress=False)\n",
    "\n",
    "\n",
    "make_fig(\n",
    "    data_path = 'data/combined_extra.csv',\n",
    "    nam_data_path = 'data/nam_data.csv',\n",
    "    item = 'time',\n",
    "    norm = True,\n",
    "    figname = 'interest_by_nam',\n",
    "    save_to = 'figures',\n",
    "    save_as = '' # File format (png, jpeg, svg, ...)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Relationship between time and interest by group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T16:16:34.792251Z",
     "start_time": "2021-02-16T16:16:32.726238Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def prepare_data(data_path, ratings_data_path):\n",
    "    # Load data of activity choices during free play\n",
    "    df = pd.read_csv(data_path).filter(items=['sid','nam','trial','abst1','abst2','abst3','abst4'])\n",
    "    df = df.loc[df.trial.eq(250) & df.nam.gt(0), :].drop(columns='trial')\n",
    "    df = pd.wide_to_long(df, stubnames='abst', i=['sid','nam'], j='act_ind').reset_index()\n",
    "    df['activity'] = 'A'+df.act_ind.astype(str)\n",
    "    df = df.drop(columns='act_ind')\n",
    "    df = df.rename(columns={'abst': 'time'})\n",
    "    \n",
    "    # Merge with interest rating data\n",
    "    ratings_df = pd.read_csv(ratings_data_path)\n",
    "    ratings_df = ratings_df.loc[ratings_df.item.eq('int'), :]\n",
    "    df = df.merge(ratings_df.drop(columns='item'), on=['sid', 'activity'])\n",
    "    return df\n",
    "\n",
    "\n",
    "def subplot_a(ax, df):\n",
    "    for group in [0, 1]:\n",
    "        x = df.loc[df.group.eq(group), 'time']\n",
    "        y = df.loc[df.group.eq(group), 'rating_norm']\n",
    "        sns.regplot(x=x, y=y, color=gcolors[group], \n",
    "                    ax=ax, scatter_kws={'alpha': .3, 's': 5})\n",
    "        ax.set_xlabel('Number of trials')\n",
    "        ax.set_ylabel('Interest rating\\n(Mean centered)')\n",
    "        \n",
    "        \n",
    "def subplot_b(axes, df):\n",
    "    for group in [0, 1]:\n",
    "        ax = axes[group]\n",
    "        for nam in [1, 2, 3]:\n",
    "            x = df.loc[df.group.eq(group) & df.nam.eq(nam), 'time']\n",
    "            y = df.loc[df.group.eq(group) & df.nam.eq(nam), 'rating_norm']\n",
    "            sns.regplot(x=x, y=y, color=ncolors[nam-1], \n",
    "                        ax=ax, scatter_kws={'alpha': .3, 's': 5})\n",
    "        ax.set_ylabel('Interest rating\\n(Mean centered)')\n",
    "        ax.set_xlabel('Number of trials')\n",
    "        ax.set_title(fullglabels[group], color=gcolors[group], fontweight='bold')\n",
    "            \n",
    "\n",
    "\n",
    "def make_fig(modeling_data_path, ratings_data_path, figname, save_to, save_as=None):\n",
    "    # Load data and create figure\n",
    "    df = prepare_data(modeling_data_path, ratings_data_path)\n",
    "    fig = plt.figure(figname, figsize=[9, 3])\n",
    "    \n",
    "    # Plot relationship between interest and time by group\n",
    "    ax = vut.pretty(fig.add_subplot(1,3,1))\n",
    "    subplot_a(ax, df)\n",
    "    lm = ols('rating ~ C(group) * time', data=df)\n",
    "    display(lm.fit().summary())\n",
    "    \n",
    "    # Plot relationship between interest and time by NAM in each group\n",
    "    axes = [vut.pretty(fig.add_subplot(1,3,2)), vut.pretty(fig.add_subplot(1,3,3))]\n",
    "    subplot_b(axes, df)\n",
    "    for group in [0, 1]:\n",
    "        print('==='*20)\n",
    "        lm = ols('rating ~ C(nam) * time', data=df.loc[df.group.eq(group), :])\n",
    "        display(lm.fit().summary())\n",
    "        \n",
    "\n",
    "    fig.tight_layout()\n",
    "    if save_as:\n",
    "        vut.save_it(fig, save_to, figname, save_as=save_as, compress=False)\n",
    "\n",
    "\n",
    "make_fig(\n",
    "    modeling_data_path='data/model_data.csv', \n",
    "    ratings_data_path='data/combined_extra.csv',\n",
    "    figname = 'interest_time_reg',\n",
    "    save_to = 'figures',\n",
    "    save_as = '' # File format (png, jpeg, svg, ...)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Individual model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T16:16:53.987688Z",
     "start_time": "2021-02-16T16:16:51.918861Z"
    },
    "code_folding": [
     0
    ],
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def main(data_path, sid, n_max, n_stop, init_dict, figname, save_to='', save_as=''):\n",
    "    # Load data\n",
    "    sdf = lut.get_sdf('data/model_data.csv', sid)\n",
    "    resps = sdf.correct.values.astype(float)\n",
    "\n",
    "    # Create model\n",
    "    model = SoftmaxChoiceModel(\n",
    "        objective = neg_log_likelihood,\n",
    "        data = sdf,\n",
    "        init_dict = init_dict,\n",
    "        hist = True\n",
    "    )\n",
    "    \n",
    "    # Fit and visualize\n",
    "    fig = plt.figure('Data transformation', figsize=[7.5, 10])\n",
    "    gs = GridSpec(3+len(model.components), 2, height_ratios=[1,1,1,1,.5], width_ratios=[.05, 1])\n",
    "\n",
    "    # Transform data\n",
    "    model.transform_inp_data(normalize)\n",
    "\n",
    "    # Fit\n",
    "    model.n_best_stop(n_stop=n_stop, max_iter=n_max, show_progress=True)\n",
    "    print(model.params[-1])\n",
    "\n",
    "    # Plot utility components\n",
    "    for j, comp in enumerate(model.components):\n",
    "        vut.add_subplot_label(x=1, y=1, label='ab'[j], size=20, ax=fig.add_subplot(gs[j, 0]))\n",
    "        ax = vut.pretty(ax = fig.add_subplot(gs[j, 1]))\n",
    "        ax.set_prop_cycle('color', colors)\n",
    "        ax.plot(model.fit_data[j])\n",
    "        ax.set_ylabel('Recent '+comp[1:].upper())\n",
    "        ax.set_xlim(1, 250)\n",
    "        ax.set_ylim(-.05, 1.05)\n",
    "        ax.axhline(0, color='gray', ls=':')\n",
    "        ax.tick_params(labelbottom=False)\n",
    "    \n",
    "    # Plot utility and predictions\n",
    "    u, p = model.get_predictions()\n",
    "    vut.add_subplot_label(x=1, y=1, label='c', size=20, ax=fig.add_subplot(gs[len(model.components)+0, 0]))\n",
    "    ax = vut.pretty(fig.add_subplot(gs[len(model.components)+0, 1]))\n",
    "    ax.set_prop_cycle('color', colors)\n",
    "    ax.plot(u)\n",
    "    ax.set_xlim(1, 250)\n",
    "    ax.tick_params(labelbottom=False)\n",
    "    ax.set_ylabel('Utility')\n",
    "    params = model.params[:-1]\n",
    "    norm_params = params / np.sqrt(np.sum(params*params))\n",
    "    signs = [[r'$+$ ', r'$-$ '][int(p < 0)] for p in norm_params]\n",
    "    t = r'$U$ ='\n",
    "    for ind, (sign, coef, comp) in enumerate(zip(signs, norm_params, model.components)):\n",
    "        if ind==0 and coef >= 0: \n",
    "            sign=''\n",
    "        t = t + fr' {sign}{np.abs(coef):.2f}$\\times {comp[1:].upper()}$'\n",
    "    ax.set_title(t, fontsize=14, loc='right', pad=-5)\n",
    "    \n",
    "    vut.add_subplot_label(x=1, y=1, label='d', size=20, ax=fig.add_subplot(gs[len(model.components)+1, 0]))\n",
    "    ax = vut.pretty(fig.add_subplot(gs[len(model.components)+1, 1]))\n",
    "    ax.set_prop_cycle('color', colors)\n",
    "    ax.plot(p)\n",
    "    ax.set_xlim(1, 250)\n",
    "    ax.set_ylim(0, 1.05)\n",
    "    ax.tick_params(labelbottom=False)\n",
    "    ax.set_ylabel('Probability')\n",
    "    \n",
    "    legend_elements = [Patch(facecolor=c, label=l) for c,l in zip(colors, tlabels.values())]\n",
    "    ax.legend(handles=legend_elements, bbox_to_anchor=[0.5, 1.1], loc='center', ncol=4)\n",
    "    \n",
    "    # Plot subject data\n",
    "    vut.add_subplot_label(x=1, y=1, label='e', size=20, ax=fig.add_subplot(gs[len(model.components)+2, 0]))\n",
    "    ax = vut.pretty(fig.add_subplot(gs[len(model.components)+2, 1]))\n",
    "    ax.set_xlim(1, 250)\n",
    "    x = np.arange(1, 250)\n",
    "    for i in [0,1,2,3]:\n",
    "        y = np.zeros_like(x)+.2\n",
    "        mask = model.choice_data[:, i].astype(bool)\n",
    "        y[~mask] = np.nan\n",
    "        ax.plot(x, y, c=colors[i], lw=10)\n",
    "    resps[~resps.astype(bool)] = np.nan\n",
    "    ax.plot(resps*.4, ls='', marker='|', color='k')\n",
    "    ax.set_ylim(0, 1)\n",
    "    vut.despine(ax, ['left','right','top'])\n",
    "    ax.set_ylabel('Actual choices\\nand responses', labelpad=25)\n",
    "    ax.set_xlabel('Trial')\n",
    "    ax.tick_params(labelleft=False, left=False)\n",
    "    legend_elements = [\n",
    "        Line2D([0],[0], ls='', marker='|', color='k', label='Correct guesses')\n",
    "    ]\n",
    "    ax.legend(handles=legend_elements, bbox_to_anchor=[0.5, 1], loc='center')\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    fig.subplots_adjust(hspace=.3, right=.90)\n",
    "    if save_as:\n",
    "        vut.save_it(fig, save_to, figname, \n",
    "            save_as=save_as, compress=False, dpi=100)\n",
    "\n",
    "    \n",
    "main(\n",
    "    data_path = 'data/model_data.csv',\n",
    "    sid = 104,\n",
    "    n_max = 500,\n",
    "    n_stop = 10,\n",
    "    init_dict = {\n",
    "        # 'param_handle': (init_range, apply_boundary)\n",
    "        'rpc':([-1,1], True),\n",
    "        'rlp':([-1,1], True),\n",
    "        'tau': ([0,100], True),\n",
    "    },\n",
    "    figname = 'sm_fig1',\n",
    "    save_to = 'figures',\n",
    "    save_as = ''\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Group level coefficients and behavior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-22T08:35:22.014942Z",
     "start_time": "2020-12-22T08:35:21.990115Z"
    },
    "code_folding": [
     0
    ],
    "hidden": true,
    "run_control": {
     "marked": false
    },
    "scrolled": false
   },
   "source": [
    "Effect sizes conventions for reference\n",
    "\n",
    "|Effect size|*d*|\n",
    "|---|---|\n",
    "|Very small|0.01|\n",
    "|Small|0.20|\n",
    "|Medium|0.50|\n",
    "|Large|0.80|\n",
    "|Very large|1.20|\n",
    "|Huge|2.0|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Full version\n",
    "(includes all groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T16:22:02.960319Z",
     "start_time": "2021-02-16T16:21:55.984984Z"
    },
    "code_folding": [
     0,
     28,
     66,
     83
    ],
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def load_data(heuristics_data_path, params_data_path, learning_data_path, nq=1, nam=None):\n",
    "    idx = pd.IndexSlice\n",
    "    # Heuristics dataset\n",
    "    hdf = pd.read_csv(heuristics_data_path)\n",
    "    # Params dataset\n",
    "    pdf = pd.read_csv(params_data_path)\n",
    "    pdf = pdf.loc[pdf.vars.eq('rpc,rlp'), :]\n",
    "    # Learning dataset\n",
    "    ldf = pd.read_csv(learning_data_path)\n",
    "    # Optionally, filter by NAM\n",
    "    if nam: \n",
    "        hdf = df.loc[hdf.nam.eq(nam), :]\n",
    "        pdf = df.loc[pdf.nam.eq(nam), :]\n",
    "    # Get normalized coefficient values and label quantiles\n",
    "    norm = np.linalg.norm(pdf.loc[:, 'rpc':'rlp'].values, axis=1)\n",
    "    pdf['norm_rpc'] = pdf.rpc / norm\n",
    "    pdf['norm_rlp'] = pdf.rlp / norm\n",
    "#     pdf['qi_rpc'] = pd.qcut(pdf.norm_rpc, q=nq)\n",
    "#     pdf['qi_rlp'] = pd.qcut(pdf.norm_rlp, q=nq)\n",
    "    pdf['qi_rpc'] = pd.cut(pdf.norm_rpc, bins=nq)\n",
    "    pdf['qi_rlp'] = pd.cut(pdf.norm_rlp, bins=nq)\n",
    "    # Select columns in each df\n",
    "    pcols = ['sid','group','nam','rpc', 'rlp', 'norm_rpc', 'norm_rlp', 'qi_rpc', 'qi_rlp']\n",
    "    hcols = ['sid', 'group', 'trial'] + [i for sub in [[v+si for si in '1234'] for v in ['rpc', 'rlp', 'ch']] for i in sub]\n",
    "    lcols = ['sid', 'dwfpc', 'dwipc']\n",
    "    return {'p': pdf.filter(items=pcols), 'h': hdf.filter(items=hcols), 'l': ldf.filter(items=lcols)}\n",
    "\n",
    "\n",
    "def subfig_a(axes, df, qi_rlp, qi_rpc, bins=25):\n",
    "    # Group offsets\n",
    "    off = [-.05, .05]\n",
    "    # Bin data\n",
    "    qrlp = df.qi_rlp.unique()[qi_rlp]\n",
    "    qrpc = df.qi_rpc.unique()[qi_rpc]\n",
    "    # Plot joint data\n",
    "    for group in [0, 1]:\n",
    "        ax = axes[1]\n",
    "        grp_flt = df.group.eq(group)\n",
    "        q_flt = df.qi_rlp.eq(qrlp) & df.qi_rpc.eq(qrpc)\n",
    "        ax.scatter(\n",
    "            df.loc[grp_flt & ~q_flt, 'norm_rlp']+off[group],\n",
    "            df.loc[grp_flt & ~q_flt, 'norm_rpc']+off[group],\n",
    "            alpha=.05, color=gcolors[group], marker='o', s=5)\n",
    "        ax.scatter(\n",
    "            df.loc[grp_flt & q_flt, 'norm_rlp']+off[group],\n",
    "            df.loc[grp_flt & q_flt, 'norm_rpc']+off[group],\n",
    "            alpha=.3, color=gcolors[group], marker='o', s=10)\n",
    "    ax.text(0, 0, 'N = {:}'.format(q_flt.sum()), ha='center', va='center')\n",
    "#         display(df.groupby('group')[['norm_rpc','norm_rlp']].agg(['mean','sem']))\n",
    "    # Plot marginal data\n",
    "    sns.histplot(x='norm_rlp', data=df, ax=axes[0], stat='probability', bins=bins, element='step', color='gray')\n",
    "    axes[0].axvspan(qrlp.left, qrlp.right, color='magenta', alpha=.2)\n",
    "    sns.histplot(y='norm_rpc', data=df, ax=axes[2], stat='probability', bins=bins, element='step', color='gray')\n",
    "    axes[2].axhspan(qrpc.left, qrpc.right, color='magenta', alpha=.2)\n",
    "    # Labels\n",
    "    for ax in (axes[0], axes[2]):\n",
    "        ax.set_xlabel('')\n",
    "        ax.set_ylabel('')\n",
    "    axes[0].tick_params(labelbottom=False)\n",
    "    axes[2].tick_params(labelleft=False, labelrotation=-90)\n",
    "    axes[0].set_xlabel(r'$w_{LP}$')\n",
    "    axes[0].xaxis.set_label_position('top')\n",
    "    axes[2].set_ylabel(r'$w_{PC}$', rotation=-90, va='top')\n",
    "    axes[2].yaxis.set_label_position('right')\n",
    "\n",
    "\n",
    "def subfig_var(ax, df, variable, errb=False, sample_size=False, lw=2):\n",
    "    idx = pd.IndexSlice\n",
    "    ax.set_prop_cycle(cycler(color=colors))\n",
    "    grouped = df.groupby('trial').agg(['mean', 'sem'])\n",
    "    s = (variable+'{}').format\n",
    "    y = grouped.loc[:, idx[s(1):s(4), 'mean']].values\n",
    "    x = np.stack([np.arange(y.shape[0]) for i in range(y.shape[1])], axis=1)\n",
    "    yerr = grouped.loc[:, idx[s(1):s(4), 'sem']].values\n",
    "    ax.plot(x, y, lw=1)\n",
    "    if errb:\n",
    "        for i in range(x.shape[1]):\n",
    "            ax.fill_between(x[:, i], y1=y[:, i]+yerr[:, i], y2=y[:, i]-yerr[:, i], alpha=.2)\n",
    "    ax.set_xlim(0, 250)\n",
    "    if sample_size:\n",
    "        ax.set_title('N = {}'.format(len(df.sid.unique())))\n",
    "\n",
    "        \n",
    "def subfig_stats(ax, df):\n",
    "    t, pval = scs.ttest_rel(df.dwipc, df.dwfpc)\n",
    "    d = (df.dwfpc.mean() - df.dwipc.mean()) / np.sqrt((df.dwfpc.std()**2 + df.dwipc.std()**2)/2)\n",
    "    df = df.melt()\n",
    "    df = df.replace({'dwfpc': 'dwfPC', 'dwipc': 'dwiPC'})\n",
    "    sns.barplot(\n",
    "        x='variable', y='value', data=df, order=['dwiPC', 'dwfPC'], ax=ax,\n",
    "        linewidth=1, facecolor=(1, 1, 1, 0), errcolor='k', edgecolor='k'\n",
    "    )\n",
    "    ax.text(.5, .90, r'$d={:.3f}^*$'.format(d, pval), va='top', ha='center')\n",
    "    ax.set_xlabel(''); ax.set_ylabel('')\n",
    "    vut.change_width(ax, .6)\n",
    "    \n",
    "\n",
    "def make_fig(nq, figname, save_to, save_as=''):\n",
    "    nrows, ncols = 5+1, (nq**2-1)\n",
    "    fig = plt.figure(num=figname, figsize=[2.5 + 2*ncols, 8])\n",
    "    subfig_ratios = [.7, .4]\n",
    "    gs = fig.add_gridspec(\n",
    "        ncols = 1 + ncols, \n",
    "        nrows = nrows, \n",
    "        width_ratios = [.1] + list(np.ones(ncols)),\n",
    "        height_ratios = [2] + list(np.ones(nrows-1) + [.25])\n",
    "    )\n",
    "    add = fig.add_subplot\n",
    "    \n",
    "    # Load data\n",
    "    data = load_data(\n",
    "        heuristics_data_path = 'data/model_data.csv',\n",
    "        params_data_path = 'data/model_results/param_fits_clean.csv',\n",
    "        learning_data_path = 'data/learning_data.csv',\n",
    "        nam = None,\n",
    "        nq = nq\n",
    "    )\n",
    "    \n",
    "    # Annotate figure rows\n",
    "    for i, letter in enumerate('abcde'):\n",
    "        vut.add_subplot_label(x=0, y=1, label=letter, size=18, ax=fig.add_subplot(gs[i, 0]))\n",
    "    \n",
    "    # Plot data\n",
    "    qs_rlp = data['p'].qi_rlp.unique()\n",
    "    qs_rpc = data['p'].qi_rpc.unique()\n",
    "    # Order according to \n",
    "    for ci, (i, j) in enumerate(zip([0,1,2,0,2,2,0,1], [0,2,2,2,0,1,1,1]), 1):\n",
    "        # Subplot (a)\n",
    "        main_ax = vut.pretty(add(gs[0, ci], aspect='equal'))\n",
    "        divider = make_axes_locatable(main_ax)\n",
    "        marg_ax1 = vut.pretty(divider.append_axes('top', '30%', pad=0.2, sharex=main_ax))\n",
    "        marg_ax2 = vut.pretty(divider.append_axes('right', '30%', pad=0.2, sharey=main_ax))\n",
    "        axes = [marg_ax1, main_ax, marg_ax2]\n",
    "        subfig_a(axes, data['p'], qi_rlp=i, qi_rpc=j)\n",
    "\n",
    "        # Filter sids for subplots (b) to (e)\n",
    "        sids = data['p'].loc[\n",
    "                data['p'].qi_rlp.eq(qs_rlp[i]) & data['p'].qi_rpc.eq(qs_rpc[j])\n",
    "            ].sid.unique()\n",
    "\n",
    "        # Select data for subplots (b) to (d)\n",
    "        df = data['h'].set_index('sid').loc[sids, :].reset_index()\n",
    "\n",
    "        # Subplot (b)\n",
    "        ax = vut.pretty(add(gs[1, ci]))\n",
    "        subfig_var(ax, df, variable='ch', errb=False)\n",
    "        ax.set_ylim(0, 0.75)\n",
    "        if ci == 1: \n",
    "            ax.set_ylabel('% selection')\n",
    "\n",
    "        # Subplot (c)\n",
    "        ax = vut.pretty(add(gs[2, ci]))\n",
    "        subfig_var(ax, df, variable='rlp', errb=True)\n",
    "        ax.set_ylim(0.03, 0.25)\n",
    "        if ci == 1:\n",
    "            ax.set_ylabel('Recent LP')\n",
    "\n",
    "        # Subplot (d)\n",
    "        ax = vut.pretty(add(gs[3, ci]))\n",
    "        subfig_var(ax, df, variable='rpc', errb=True)\n",
    "        ax.set_ylim(0.45, 0.92)\n",
    "        if ci == 1:\n",
    "            ax.set_ylabel('Recent PC')\n",
    "\n",
    "        # Subplot (e)\n",
    "        # Select data for subplots (e)\n",
    "        df = data['l'].set_index('sid').loc[sids, :]\n",
    "        ax = vut.pretty(add(gs[4, ci]))\n",
    "        subfig_stats(ax, df)\n",
    "        ax.set_ylim(.5, .9)\n",
    "        if ci == 1:\n",
    "            ax.set_ylabel('score')\n",
    "            \n",
    "    # Add legend\n",
    "    ax = vut.ghost(add(gs[5, 1:]))\n",
    "    handles = [lines.Line2D([0], [0], color=colors[k], ls='', marker='o', label=tlabels[k + 1]) for k in range(4)]\n",
    "    handles += [lines.Line2D([0], [0], ls='', marker='o', markerfacecolor=c, markeredgecolor=c, color=c) for c in gcolors]\n",
    "    legw, legh = .25, .2\n",
    "    leg = ax.legend(handles, list(tlabels.values())+list(fullglabels.values()), handletextpad=.05,\n",
    "                    bbox_to_anchor=(.5-legw/2, .5, legw, legh), loc='center', mode='expand', ncol=3)\n",
    "    vut.color_legend(leg)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    fig.subplots_adjust(hspace=.4)\n",
    "    if save_as:\n",
    "        vut.save_it(fig, save_to, figname=figname, save_as=save_as, compress=False, dpi=100)\n",
    "    \n",
    "    \n",
    "make_fig(\n",
    "    nq = 3,\n",
    "    figname = 'sm_fig2a',\n",
    "    save_to = 'figures',\n",
    "    save_as = '' # File format (png, jpeg, svg, ...)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Simplified version\n",
    "(include only cardinal groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T16:23:22.962820Z",
     "start_time": "2021-02-16T16:23:19.367981Z"
    },
    "code_folding": [
     0,
     66,
     103
    ],
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def load_data(heuristics_data_path, params_data_path, learning_data_path, nq=1, nam=None):\n",
    "    idx = pd.IndexSlice\n",
    "    # Heuristics dataset\n",
    "    hdf = pd.read_csv(heuristics_data_path)\n",
    "    # Params dataset\n",
    "    pdf = pd.read_csv(params_data_path)\n",
    "    pdf = pdf.loc[pdf.vars.eq('rpc,rlp'), :]\n",
    "    # Learning dataset\n",
    "    ldf = pd.read_csv(learning_data_path)\n",
    "    # Optionally, filter by NAM\n",
    "    if nam: \n",
    "        hdf = df.loc[hdf.nam.eq(nam), :]\n",
    "        pdf = df.loc[pdf.nam.eq(nam), :]\n",
    "    # Get normalized coefficient values and label quantiles\n",
    "    norm = np.linalg.norm(pdf.loc[:, 'rpc':'rlp'].values, axis=1)\n",
    "    pdf['norm_rpc'] = pdf.rpc / norm\n",
    "    pdf['norm_rlp'] = pdf.rlp / norm\n",
    "#     pdf['qi_rpc'] = pd.qcut(pdf.norm_rpc, q=nq)\n",
    "#     pdf['qi_rlp'] = pd.qcut(pdf.norm_rlp, q=nq)\n",
    "    pdf['qi_rpc'] = pd.cut(pdf.norm_rpc, bins=nq)\n",
    "    pdf['qi_rlp'] = pd.cut(pdf.norm_rlp, bins=nq)\n",
    "    # Select columns in each df\n",
    "    pcols = ['sid','group','nam','rpc', 'rlp', 'norm_rpc', 'norm_rlp', 'qi_rpc', 'qi_rlp']\n",
    "    hcols = ['sid', 'group', 'trial'] + [i for sub in [[v+si for si in '1234'] for v in ['rpc', 'rlp', 'ch']] for i in sub]\n",
    "    lcols = ['sid', 'dwfpc', 'dwipc']\n",
    "    return {'p': pdf.filter(items=pcols), 'h': hdf.filter(items=hcols), 'l': ldf.filter(items=lcols)}\n",
    "\n",
    "\n",
    "def subfig_a(axes, df, qi_rlp, qi_rpc, bins=25):\n",
    "    # Group offsets\n",
    "    off = [-.05, .05]\n",
    "    # Bin data\n",
    "    qrlp = df.qi_rlp.unique()[qi_rlp]\n",
    "    qrpc = df.qi_rpc.unique()[qi_rpc]\n",
    "    # Plot joint data\n",
    "    for group in [0, 1]:\n",
    "        ax = axes[1]\n",
    "        grp_flt = df.group.eq(group)\n",
    "        q_flt = df.qi_rlp.eq(qrlp) & df.qi_rpc.eq(qrpc)\n",
    "        ax.scatter(\n",
    "            df.loc[grp_flt & ~q_flt, 'norm_rlp']+off[group],\n",
    "            df.loc[grp_flt & ~q_flt, 'norm_rpc']+off[group],\n",
    "            alpha=.05, color=gcolors[group], marker='o', s=5)\n",
    "        ax.scatter(\n",
    "            df.loc[grp_flt & q_flt, 'norm_rlp']+off[group],\n",
    "            df.loc[grp_flt & q_flt, 'norm_rpc']+off[group],\n",
    "            alpha=.3, color=gcolors[group], marker='o', s=10)\n",
    "    ax.text(0, 0, 'N = {:}'.format(q_flt.sum()), ha='center', va='center')\n",
    "#         display(df.groupby('group')[['norm_rpc','norm_rlp']].agg(['mean','sem']))\n",
    "    # Plot marginal data\n",
    "    sns.histplot(x='norm_rlp', data=df, ax=axes[0], stat='probability', bins=bins, element='step', color='gray')\n",
    "    axes[0].axvspan(qrlp.left, qrlp.right, color='magenta', alpha=.2)\n",
    "    sns.histplot(y='norm_rpc', data=df, ax=axes[2], stat='probability', bins=bins, element='step', color='gray')\n",
    "    axes[2].axhspan(qrpc.left, qrpc.right, color='magenta', alpha=.2)\n",
    "    # Labels\n",
    "    for ax in (axes[0], axes[2]):\n",
    "        ax.set_xlabel('')\n",
    "        ax.set_ylabel('')\n",
    "    axes[0].tick_params(labelbottom=False)\n",
    "    axes[2].tick_params(labelleft=False, labelrotation=-90)\n",
    "    axes[0].set_xlabel(r'$w_{LP}$')\n",
    "    axes[0].xaxis.set_label_position('top')\n",
    "    axes[2].set_ylabel(r'$w_{PC}$', rotation=-90, va='top', labelpad=15)\n",
    "    axes[2].yaxis.set_label_position('right')\n",
    "\n",
    "    \n",
    "def subfig_var(ax, df, variable, errb=False, sample_size=False, lw=2):\n",
    "    idx = pd.IndexSlice\n",
    "    ax.set_prop_cycle(cycler(color=colors))\n",
    "    grouped = df.groupby('trial').agg(['mean', 'sem'])\n",
    "    s = (variable+'{}').format\n",
    "    y = grouped.loc[:, idx[s(1):s(4), 'mean']].values\n",
    "    x = np.stack([np.arange(y.shape[0]) for i in range(y.shape[1])], axis=1)\n",
    "    yerr = grouped.loc[:, idx[s(1):s(4), 'sem']].values\n",
    "    ax.plot(x, y, lw=1)\n",
    "    if errb:\n",
    "        for i in range(x.shape[1]):\n",
    "            ax.fill_between(x[:, i], y1=y[:, i]+yerr[:, i], y2=y[:, i]-yerr[:, i], alpha=.2)\n",
    "    ax.set_xlim(0, 250)\n",
    "    if sample_size:\n",
    "        ax.set_title('N = {}'.format(len(df.sid.unique())))\n",
    "    \n",
    "        \n",
    "def subfig_choices(ax, df):\n",
    "    # Compute stats\n",
    "    df = df.copy().set_index(['sid', 'group'])\n",
    "    df = df.groupby(['sid', 'group']).sum()[['ch1','ch2','ch3','ch4']]/250 * 100\n",
    "    df = df.reset_index()\n",
    "    df = df.groupby(['group']).agg(['mean', 'sem'])\n",
    "    df.columns = df.columns.map('_'.join)\n",
    "    # Group offsets\n",
    "    off = [-.05, .05]\n",
    "    for group in [0, 1]:\n",
    "        mean = df.loc[group, [f'ch{i}_mean' for i in '1234']]\n",
    "        sem = df.loc[group, [f'ch{i}_sem' for i in '1234']]\n",
    "        ax.errorbar(x=np.arange(4)+off[group], y=mean, yerr=sem, color=gcolors[group], marker='os'[group])\n",
    "    ax.set_ylim(0, 60)\n",
    "    ax.set_xticks(np.arange(4))\n",
    "    ax.set_xticklabels(['A1', 'A2', 'A3', 'A4'], fontweight='bold')\n",
    "    for xt, c in zip(ax.get_xticklabels(), colors):\n",
    "        xt.set_color(c)\n",
    "\n",
    "        \n",
    "def subfig_stats(ax, df):\n",
    "    t, pval = scs.ttest_rel(df.dwipc, df.dwfpc)\n",
    "    d = (df.dwfpc.mean() - df.dwipc.mean()) / np.sqrt((df.dwfpc.std()**2 + df.dwipc.std()**2)/2)\n",
    "    df = df.melt()\n",
    "    df = df.replace({'dwfpc': 'dwfPC', 'dwipc': 'dwiPC'})\n",
    "    sns.barplot(\n",
    "        x='variable', y='value', data=df, order=['dwiPC', 'dwfPC'], ax=ax,\n",
    "        linewidth=1, facecolor=(1, 1, 1, 0), errcolor='k', edgecolor='k'\n",
    "    )\n",
    "    ax.text(.5, .90, r'$d={:.3f}^*$'.format(d, pval), va='top', ha='center')\n",
    "    ax.set_xlabel(''); ax.set_ylabel('')\n",
    "    vut.change_width(ax, .6)\n",
    "    \n",
    "\n",
    "def make_fig(nq, figname, save_to, save_as=''):\n",
    "    nrows, ncols = 4+1, (nq**2-1)-4\n",
    "    fig = plt.figure(num=figname, figsize=[2.5 + 2*ncols, 8])\n",
    "    subfig_ratios = [.7, .4]\n",
    "    gs = fig.add_gridspec(\n",
    "        ncols = 1 + ncols, \n",
    "        nrows = nrows, \n",
    "        width_ratios = [.1] + list(np.ones(ncols)),\n",
    "        height_ratios = [2] + list(np.ones(nrows-1) + [.25])\n",
    "    )\n",
    "    add = fig.add_subplot\n",
    "    \n",
    "    # Load data\n",
    "    data = load_data(\n",
    "        heuristics_data_path = 'data/model_data.csv',\n",
    "        params_data_path = 'data/model_results/param_fits_clean.csv',\n",
    "        learning_data_path = 'data/learning_data.csv',\n",
    "        nam = None,\n",
    "        nq = nq\n",
    "    )\n",
    "    \n",
    "    # Annotate figure rows\n",
    "    for i, letter in enumerate('abcd'):\n",
    "        vut.add_subplot_label(x=0, y=1, label=letter, size=18, ax=fig.add_subplot(gs[i, 0]))\n",
    "    \n",
    "    # Plot data\n",
    "    qs_rlp = data['p'].qi_rlp.unique()\n",
    "    qs_rpc = data['p'].qi_rpc.unique()\n",
    "    # Order according to \n",
    "#     for ci, (i, j) in enumerate(zip([0,1,2,0,2,2,0,1], [0,2,2,2,0,1,1,1]), 1):\n",
    "    for ci, (i, j) in enumerate(zip([0,1,2,1], [0,2,0,1]), 1):\n",
    "        # Subplot (a)\n",
    "        main_ax = vut.pretty(add(gs[0, ci], aspect='equal'))\n",
    "        divider = make_axes_locatable(main_ax)\n",
    "        marg_ax1 = vut.pretty(divider.append_axes('top', '30%', pad=0.2, sharex=main_ax))\n",
    "        marg_ax2 = vut.pretty(divider.append_axes('right', '30%', pad=0.2, sharey=main_ax))\n",
    "        axes = [marg_ax1, main_ax, marg_ax2]\n",
    "        subfig_a(axes, data['p'], qi_rlp=i, qi_rpc=j)\n",
    "\n",
    "        # Filter sids for subplots (b) to (e)\n",
    "        sids = data['p'].loc[\n",
    "                data['p'].qi_rlp.eq(qs_rlp[i]) & data['p'].qi_rpc.eq(qs_rpc[j])\n",
    "            ].sid.unique()\n",
    "\n",
    "        # Select data for subplots (b) to (d)\n",
    "        df = data['h'].set_index('sid').loc[sids, :].reset_index()\n",
    "\n",
    "        # Subplot (b)\n",
    "        ax = vut.pretty(add(gs[1, ci]))\n",
    "        subfig_var(ax, df, variable='ch', errb=False)\n",
    "        ax.set_ylim(0, 0.75)\n",
    "        if ci == 1: \n",
    "            ax.set_ylabel('selection\\nrates (%)')\n",
    "\n",
    "        # Subplot (c)\n",
    "        ax = vut.pretty(add(gs[2, ci]))\n",
    "        subfig_choices(ax, df)\n",
    "        ax.set_xlim(-.5, 3.5)\n",
    "        if ci == 1:\n",
    "            ax.set_ylabel('time\\nallocation (%)')\n",
    "\n",
    "        # Subplot (d)\n",
    "        df = data['l'].set_index('sid').loc[sids, :]\n",
    "        ax = vut.pretty(add(gs[3, ci]))\n",
    "        subfig_stats(ax, df)\n",
    "        ax.set_ylim(.5, .9)\n",
    "        if ci == 1:\n",
    "            ax.set_ylabel('score')\n",
    "            \n",
    "    # Add legend\n",
    "    ax = vut.ghost(add(gs[4, 1:]))\n",
    "    handles = [lines.Line2D([0], [0], color=colors[k], ls='', marker='o', label=tlabels[k + 1]) for k in range(4)]\n",
    "    handles += [lines.Line2D([0], [0], ls='', marker='o', markerfacecolor=c, markeredgecolor=c, color=c) for c in gcolors]\n",
    "    legw, legh = .25, .2\n",
    "    leg = ax.legend(handles, list(tlabels.values())+list(fullglabels.values()), handletextpad=.05,\n",
    "                    bbox_to_anchor=(.5-legw/2, .5, legw, legh), loc='center', mode='expand', ncol=3)\n",
    "    vut.color_legend(leg)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    fig.subplots_adjust(hspace=.4)\n",
    "    if save_as:\n",
    "        vut.save_it(fig, save_to, figname=figname, save_as=save_as, compress=False, dpi=100)\n",
    "    \n",
    "    \n",
    "make_fig(\n",
    "    nq = 3,\n",
    "    figname = 'sm_fig2b',\n",
    "    save_to = 'figures',\n",
    "    save_as = '' # File format (png, jpeg, svg, ...)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Model comparisons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Split by groups and NAMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T16:24:09.020570Z",
     "start_time": "2021-02-16T16:24:08.080001Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def make_fig(data_path, figname, save_to, save_as='', __=slice(None)):\n",
    "    # Load data\n",
    "    plot_df = pd.read_csv(data_path, index_col='vars').filter(items=['group','nam','aic'])\n",
    "    plot_df = plot_df.replace(to_replace={'group': {0: 'IG', 1: 'EG'}})\n",
    "    \n",
    "    # Optionally, filter out model forms with RelT\n",
    "#     plot_df = plot_df[~plot_df.index.to_series().str.contains('relt')]\n",
    "    \n",
    "    # Relabel model forms\n",
    "    new_ind = plot_df.index.to_series().str.replace(',',' + ')\n",
    "    new_ind = new_ind.str.replace('rpc', 'PC')\n",
    "    new_ind = new_ind.str.replace('rlp', 'LP')\n",
    "    new_ind = new_ind.str.replace('abst','EXP')\n",
    "    plot_df.index = pd.Index(new_ind, name='vars')\n",
    "\n",
    "    # Calculate average scores per model form\n",
    "    df = plot_df.groupby(['group','nam','vars']).agg({'aic':['mean', 'std', 'count']})\n",
    "    df.columns = df.columns.map('_'.join)\n",
    "    df.sort_values(by=['group','nam','aic_mean'], inplace=True)\n",
    "    display(df)\n",
    "    \n",
    "    fig = plt.figure(figname, figsize=(6, 8))\n",
    "    gs = GridSpec(3, 1)\n",
    "    for i in range(3):\n",
    "        ax = vut.pretty(fig.add_subplot(gs[i, 0]), 'x')\n",
    "        plot_order = reversed(list(df.index.get_level_values(2))[:7])\n",
    "        sub_df = plot_df.loc[plot_df.nam.eq(i+1), :].reset_index()\n",
    "        sns.boxplot(\n",
    "            x='aic', y='vars', data=sub_df, ax=ax,\n",
    "            linewidth=1, order=plot_order, whis=100,\n",
    "            hue='group', palette=gcolors, saturation=1,\n",
    "        )\n",
    "        for v in ax.collections: v.set_linewidth(.5)\n",
    "        baseline_aic = get_baseline_aic(250, 4)\n",
    "        ax.axvline(baseline_aic, ls='--', zorder=3, color='orange',\n",
    "                   label='Random model')\n",
    "        ax.set_xlim([10, 800])\n",
    "        ax.tick_params(axis='both', labelsize=12)\n",
    "        ax.text(760, 3, 'NAM {}'.format(i+1))\n",
    "        \n",
    "        if i == 0: \n",
    "            ax.legend(bbox_to_anchor=[0, 1.1, 1, .2], loc='lower center', mode='expand', ncol=3)\n",
    "        else:\n",
    "            ax.legend().remove()\n",
    "            \n",
    "        if i == 1: \n",
    "            ax.set_ylabel('Model', fontsize=14)\n",
    "        else: \n",
    "            ax.set_ylabel('')\n",
    "            \n",
    "        if i == 2:\n",
    "            ax.set_xlabel('AIC', fontsize=14)\n",
    "        else:\n",
    "            ax.set_xlabel('')\n",
    "            ax.tick_params(axis='x', labelbottom=False)\n",
    "\n",
    "    print('Baseline AIC = {:.3f}'.format(baseline_aic))\n",
    "    fig.tight_layout()\n",
    "    if save_as:\n",
    "        vut.save_it(fig, save_to, figname=figname, save_as=save_as, compress=False, dpi=100)\n",
    "\n",
    "\n",
    "make_fig(\n",
    "    data_path = 'data/model_results/param_fits_clean.csv',\n",
    "    figname = 'model_comparisons_full',\n",
    "    save_to = 'figures',\n",
    "    save_as = '' # File format (png, jpeg, svg, ...)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T16:24:17.253978Z",
     "start_time": "2021-02-16T16:24:16.715453Z"
    },
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def make_fig(data_path, figname, save_to, save_as='', __=slice(None)):\n",
    "    # Load data\n",
    "    plot_df = pd.read_csv(data_path, index_col='vars').filter(items=['aic'])\n",
    "    # Relabel model forms\n",
    "    new_ind = plot_df.index.to_series().str.replace(',',' + ')\n",
    "    new_ind = new_ind.str.replace('rpc', 'PC')\n",
    "    new_ind = new_ind.str.replace('rlp', 'LP')\n",
    "    new_ind = new_ind.str.replace('abst','EXP')\n",
    "    plot_df.index = pd.Index(new_ind, name='vars')\n",
    "    # Calculate average scores per model form\n",
    "    df = plot_df.groupby('vars').agg({'aic':['mean', 'std']})\n",
    "    df.columns = df.columns.map('_'.join)\n",
    "    df.sort_values(by='aic_mean', ascending=False, inplace=True)\n",
    "    display(df)\n",
    "    # Plot data\n",
    "    fig = plt.figure(figname, figsize=(6, 6))\n",
    "    ax = vut.pretty(fig.add_subplot(111))\n",
    "    sns.stripplot(\n",
    "        x='aic', y='vars', data=plot_df.reset_index(), ax=ax,\n",
    "        color='k', alpha=.6, size=2, order=df.index\n",
    "    )\n",
    "    sns.boxplot(\n",
    "        x='aic', y='vars', data=plot_df.reset_index(), ax=ax,\n",
    "        color='lightgray', linewidth=2, order=df.index, whis=100, width=.5\n",
    "    )\n",
    "    for v in ax.collections: v.set_edgecolor('w')\n",
    "    # Add details\n",
    "    baseline_AIC = get_baseline_aic(250, 4)\n",
    "    ax.axvline(baseline_AIC, ls='--', zorder=3, color='red',\n",
    "               label='Random model')\n",
    "#     ax.legend().remove()\n",
    "    ax.set_ylabel('Model form')\n",
    "    ax.set_xlabel('AIC')\n",
    "    ax.set_xlim(50, 800)\n",
    "    ax.tick_params(labelsize=12)\n",
    "    ax.text(780, 1, 'Random model', color='red', ha='center', va='center', rotation=-90, fontsize=14)\n",
    "\n",
    "    print('Baseline AIC = {:.3f}'.format(mut.get_baseline_aic(250, 4)))\n",
    "    fig.tight_layout()\n",
    "    if save_as:\n",
    "        vut.save_it(fig, save_to, figname=figname, save_as=save_as, compress=False, dpi=100)\n",
    "\n",
    "\n",
    "make_fig(\n",
    "    data_path = 'data/model_results/param_fits_clean.csv',\n",
    "    figname = 'sm_fig3',\n",
    "    save_to = 'figures',\n",
    "    save_as = '' # File format (png, jpeg, svg, ...)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# MP-aligned plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T16:24:40.710007Z",
     "start_time": "2021-02-16T16:24:34.668820Z"
    },
    "hidden": true,
    "run_control": {
     "marked": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def make_fig(choice_data_path, xlim, boxcars, figname, save_to='figures', save_as=''):\n",
    "    df = pd.read_csv(choice_data_path).filter(\n",
    "        items=['sid','group','nam','trial','sc','activity','mp1','mp2','mp3']\n",
    "    )\n",
    "    df.activity = pd.Categorical(df.activity)\n",
    "    df.loc[:, 'activity'] = df.activity.cat.codes + 1\n",
    "    \n",
    "    fig = plt.figure(figname, figsize=[12,4])\n",
    "    gs = gridspec.GridSpec(nrows=2, ncols=8, width_ratios=[1, 0.1, 1,1, 0.1, 1,1,1])\n",
    "    # Add ghost plots to group subplots and add common labels\n",
    "    ax = fig.add_subplot(gs[:, :])\n",
    "    vut.ghost(ax)\n",
    "    ax.set_xlabel('Trials after mastery point (MP)', labelpad=30)\n",
    "    for ax in [fig.add_subplot(gs[:, 1]), fig.add_subplot(gs[:, 4])]:\n",
    "        vut.ghost(ax)\n",
    "        ax.axvline(1, lw=3, c='k')\n",
    "    for i, ax in enumerate([fig.add_subplot(gs[:, 0]), fig.add_subplot(gs[:, 2:4]), fig.add_subplot(gs[:, 5:])]):\n",
    "        vut.ghost(ax)\n",
    "        ax.set_title(f'NAM {i+1}', pad=30, fontsize=16)\n",
    "    \n",
    "    getax = lambda row, col: vut.pretty(fig.add_subplot(gs[row, col]))\n",
    "    sp_rows = []\n",
    "    for r in [0, 1]:\n",
    "        sp_rows.append({\n",
    "            1: [getax(r, 0)],\n",
    "            2: [getax(r, 2), getax(r, 3)],\n",
    "            3: [getax(r, 5), getax(r, 6), getax(r, 7)]\n",
    "        })\n",
    "    # Plot data\n",
    "    df.set_index(['sid','trial','group','nam'], inplace=True)\n",
    "    for nam in [1, 2, 3]:\n",
    "        for group in [0, 1]:\n",
    "            sub_df = df.loc[(slice(None), slice(None), group, nam), :].droplevel([2, 3])\n",
    "            for mp in range(nam):\n",
    "                sids = sub_df.index.get_level_values(0).unique().tolist()\n",
    "                mps = [sub_df.loc[(sid, 1), f'mp{mp+1}'] for sid in sids]\n",
    "                # Plot sticking\n",
    "                ax = sp_rows[0][nam][mp]\n",
    "                ax.set_xlim([1,xlim])\n",
    "                ax.set_ylim(0, 1)\n",
    "                ax.tick_params(labelbottom=False)\n",
    "                if nam > 1:\n",
    "                    ax.tick_params(labelleft=False)\n",
    "                aligned_choice = lut.boolean_indexing(\n",
    "                    [list(sub_df.loc[(sid, slice(max([mp-1,0]),250)), 'activity']) for sid, mp in zip(sids, mps)],\n",
    "                    fillval = 5\n",
    "                )\n",
    "                aligned_choice = aligned_choice[:, 0][:, np.newaxis] == aligned_choice[:, 1:]\n",
    "                mean = np.mean(aligned_choice, axis=0)\n",
    "                err = scs.sem(aligned_choice, axis=0, nan_policy='omit')\n",
    "                smooth_mean = pd.Series(mean).rolling(boxcars, min_periods=1).mean()\n",
    "                smooth_err = pd.Series(err).rolling(boxcars, min_periods=1).mean()\n",
    "                ax.plot(smooth_mean, color=gcolors[group])\n",
    "                ax.fill_between(np.arange(smooth_mean.size), smooth_mean+smooth_err, smooth_mean-smooth_err, color=gcolors[group], alpha=.3)\n",
    "                ax.set_title(f'MP {mp+1}', fontsize=14)\n",
    "                # Plot SC\n",
    "                aligned_sc = lut.boolean_indexing(\n",
    "                    [list(sub_df.loc[(sid, slice(mp,250)), 'sc']) for sid, mp in zip(sids, mps)],\n",
    "                    fillval = np.nan\n",
    "                )\n",
    "                ax = sp_rows[1][nam][mp]\n",
    "                if nam > 1:\n",
    "                    ax.tick_params(labelleft=False)\n",
    "                ax.set_ylim(0, 1)\n",
    "                ax.set_xlim([1,xlim])\n",
    "                mean = np.nanmean(aligned_sc, axis=0)\n",
    "                err = scs.sem(aligned_sc, axis=0, nan_policy='omit')\n",
    "                smooth_mean = pd.Series(mean).rolling(boxcars, min_periods=1).mean()\n",
    "                smooth_err = pd.Series(err).rolling(boxcars, min_periods=1).mean()\n",
    "                ax.plot(np.arange(smooth_mean.size), smooth_mean, color=gcolors[group])\n",
    "                ax.fill_between(np.arange(smooth_mean.size), smooth_mean+smooth_err, smooth_mean-smooth_err, color=gcolors[group], alpha=.3)\n",
    "\n",
    "\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    fig.subplots_adjust(wspace=.2)\n",
    "    if save_as:\n",
    "        vut.save_it(fig, save_to, figname=figname, save_as=save_as, compress=False, dpi=100)\n",
    "\n",
    "make_fig(\n",
    "    choice_data_path = 'data/model_data.csv',\n",
    "    xlim = 100,\n",
    "    boxcars = 15,\n",
    "    figname = 'sm_fig4a',\n",
    "    save_to = 'figures',\n",
    "    save_as = '',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Effect of learning criterion on NAM grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T16:24:57.771211Z",
     "start_time": "2021-02-16T16:24:55.493500Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def make_fig(data_path, omit_nans, figname, save_to, save_as):\n",
    "    def get_mts(df, **kwargs):\n",
    "        arr = df.values\n",
    "        mask = (arr != 0)\n",
    "        arr = np.where(mask.any(axis=0), mask.argmax(axis=0), kwargs['invalid_val'])\n",
    "        return pd.Series(arr, dtype='Int64')\n",
    "    \n",
    "    df = pd.read_csv(data_path).set_index(['group','sid'])\n",
    "    activities = [1,2,3,4]\n",
    "    \n",
    "    cols = [f'rpc{act_ind}' for act_ind in activities]\n",
    "    df = df.loc[df.stage.eq('free'), cols]\n",
    "    df = df.iloc[:-1, :]\n",
    "    \n",
    "    fractions_mastered = []\n",
    "    xx = [10,11,12,13,14]\n",
    "    for crit in xx:\n",
    "        crit_pc = df.loc[:, 'rpc1':'rpc4'] > crit/15\n",
    "        crit_pc.columns = activities[:]\n",
    "        mastered = crit_pc\n",
    "        \n",
    "        mts_df = mastered.groupby(['group','sid']).apply(get_mts, invalid_val=np.nan if omit_nans else 250)\n",
    "        mts_by_grp = mts_df.groupby('group', as_index=False)\n",
    "\n",
    "        mastered = mastered.groupby(['group','sid']).any()\n",
    "        fracs = lambda col: np.sum(col)/np.shape(col)[0]\n",
    "        fractions_mastered_df = mastered.groupby(['group']).apply(fracs).reset_index()\n",
    "        fractions_mastered_df['crit'] = crit\n",
    "        fractions_mastered.append(fractions_mastered_df)\n",
    "    \n",
    "    fractions_mastered_df = pd.concat(fractions_mastered).sort_values(['group', 'crit']).set_index(['group', 'crit'])\n",
    "    \n",
    "    fig = plt.figure(figname, figsize=[8, 3])\n",
    "    ax = fig.add_subplot(111)\n",
    "    vut.ghost(ax)\n",
    "    ax.set_xlabel('Mastery criterion (N of 15 correct)', labelpad=30, fontsize=14)\n",
    "    \n",
    "    # Display fractions of participants mastering each task in each group\n",
    "    for activity in activities:\n",
    "        ax = vut.pretty(fig.add_subplot(1, 4, activity))\n",
    "        ax.set_ylim(0,1)\n",
    "        ax.set_title(tlabels[activity], color=colors[activity-1], fontsize=14, fontweight='bold')\n",
    "        if activity == 1: \n",
    "            ax.set_ylabel('Fraction\\nmastering', fontsize=14)\n",
    "        else:\n",
    "            ax.tick_params(labelleft=False)\n",
    "        for group in [0, 1]:\n",
    "            series = fractions_mastered_df.loc[(group, slice(None)), activity]\n",
    "            x = series.index.levels[1][:].tolist()\n",
    "            y = series.tolist()\n",
    "            ax.plot(x, y, color=gcolors[group])\n",
    "            if activity==4:\n",
    "                ax.text(12.5, .80 if group else .65, fullglabels[group], \n",
    "                        fontsize=14, fontweight='bold', color=gcolors[group])\n",
    "        plt.xticks(xx, [str(i) for i in xx])\n",
    "    fig.tight_layout()\n",
    "    if save_as:\n",
    "        vut.save_it(fig, save_to, figname, save_as=save_as, compress=False)\n",
    "    \n",
    "    \n",
    "\n",
    "make_fig(\n",
    "    data_path = 'data/model_data.csv',\n",
    "    omit_nans = False,\n",
    "    figname = 'sm_fig4b',\n",
    "    save_to = 'figures',\n",
    "    save_as = ''\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Weights and SC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T16:25:07.990166Z",
     "start_time": "2021-02-16T16:25:07.413082Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def make_fig(data_path, data_path2, figname, save_to, save_as):    \n",
    "    df = pd.read_csv(data_path)\n",
    "    df = df.loc[df.vars.eq('rpc,rlp'), ['sid','group','nam','rpc','rlp']]\n",
    "    df['norm'] = np.sqrt(df.rpc**2 + df.rlp**2)\n",
    "    df['nrpc'] = df.rpc / df.norm\n",
    "    df['nrlp'] = df.rlp / df.norm\n",
    "    df = df.merge(\n",
    "        pd.read_csv(data_path2).loc[:, ['sid', 'sc_flat', 'sc_lep', 'sc_streaks', 'dwfpc', 'fpc']], on='sid')\n",
    "    print(ols('sc_flat ~ nrpc * nrlp', data=df).fit().summary())\n",
    "    \n",
    "    \n",
    "    fig = plt.figure(figname, figsize=[8, 4])\n",
    "    for i, var in enumerate(['nrpc', 'nrlp'], 1):\n",
    "        ax = vut.pretty(fig.add_subplot(1,2,i))\n",
    "        sns.regplot(\n",
    "            x=df.loc[:, var], y=df.loc[:, 'sc_flat'], ax=ax, color='k',\n",
    "            scatter_kws={'alpha': .3, 's': 20}\n",
    "        )\n",
    "        ax.set_xlabel(r'$\\hat w_{'+f'{var.upper()[-2:]}'+r'}$')\n",
    "        if i == 1:\n",
    "            ax.set_ylabel('Average SC')\n",
    "        else:\n",
    "            ax.set_ylabel('')\n",
    "            ax.tick_params(labelleft=False)\n",
    "        \n",
    "        lm = ols(fr'dwfpc ~ {var}', data=df).fit()\n",
    "        display(lm.summary())\n",
    " \n",
    "    fig.tight_layout()\n",
    "    if save_as:\n",
    "        vut.save_it(fig, save_to, figname, save_as=save_as, compress=False)\n",
    "    \n",
    "    \n",
    "\n",
    "make_fig(\n",
    "    data_path = 'data/model_results/param_fits_clean.csv',\n",
    "    data_path2 = 'data/learning_data.csv',\n",
    "    figname = 'response_fig2',\n",
    "    save_to = 'figures',\n",
    "    save_as = ''\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# PC separately for each activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T16:25:16.728640Z",
     "start_time": "2021-02-16T16:25:15.845751Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def make_fig(data_path, figname, save_to, save_as):    \n",
    "    df = pd.read_csv(data_path).filter(items=['sid','group','trial','rpc1','rpc2','rpc3','rpc4'])\n",
    "    df = df.groupby(['group','trial']).agg(['mean', 'sem'])\n",
    "    display(df.head())\n",
    "    \n",
    "    fig, ax = plt.subplots(num=figname, figsize=[6, 4])\n",
    "    vut.pretty(ax)\n",
    "    ax.set_xlim(0, 250)\n",
    "    ax.set_ylabel('recent PC\\n(Mean and SEM)')\n",
    "    ax.set_xlabel('Trial')\n",
    "    for group in [0, 1]:\n",
    "        for i, col in enumerate(['rpc1','rpc2','rpc3','rpc4']):\n",
    "            m = df.loc[(group, slice(None)), (col, 'mean')].values\n",
    "            sem = df.loc[(group, slice(None)), (col, 'sem')].values\n",
    "            ax.plot(m, c=colors[i], ls='--' if group else '-')\n",
    "            ax.fill_between(np.arange(m.size), m+sem, m-sem, color=colors[i], alpha=.4)\n",
    "            \n",
    "    legend_elements = [Line2D([0],[0], color=colors[i-1], label=f'A{i}') for i in [1,2,3,4]]\n",
    "    legend_elements += [Line2D([0],[0], color='gray', label=fullglabels[i], ls=['-','--'][i]) for i in [0,1]]\n",
    "    ax.legend(handles=legend_elements, bbox_to_anchor=(1.1, 1), loc='upper left')\n",
    " \n",
    "    fig.tight_layout()\n",
    "    if save_as:\n",
    "        vut.save_it(fig, save_to, figname, save_as=save_as, compress=False)\n",
    "    \n",
    "    \n",
    "\n",
    "make_fig(\n",
    "    data_path = 'data/model_data.csv',\n",
    "    figname = 'response_fig1',\n",
    "    save_to = 'figures',\n",
    "    save_as = ''\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
