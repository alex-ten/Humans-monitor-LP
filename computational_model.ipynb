{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-23T22:29:15.182907Z",
     "start_time": "2020-10-23T22:29:14.549074Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import utils.vis_utils as vut\n",
    "import utils.loc_utils as lut\n",
    "\n",
    "import ipywidgets as wid\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import contextlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import matplotlib as mpl\n",
    "mpl.use('Agg')\n",
    "from IPython.display import display\n",
    "from itertools import combinations\n",
    "from tqdm import tqdm_notebook, tqdm\n",
    "import numdifftools as nd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols, logit\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "from collections import OrderedDict\n",
    "import itertools\n",
    "\n",
    "colors = ['#43799d', '#cc5b46', '#ffbb00', '#71bc78', '#43799d', '#cc5b46', '#ffbb00', '#71bc78']\n",
    "gcolors = ['#008fd5', '#fc4f30', '#e5ae38', '#6d904f']\n",
    "\n",
    "glabels = {0: 'F', 1: 'S'} \n",
    "fullglabels = {0: 'Free', 1: 'Strategic'}\n",
    "\n",
    "@contextlib.contextmanager\n",
    "def temp_seed(seed):\n",
    "    state = np.random.get_state()\n",
    "    np.random.seed(seed)\n",
    "    try:\n",
    "        yield\n",
    "    finally:\n",
    "        np.random.set_state(state)\n",
    "        \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-23T22:30:30.519081Z",
     "start_time": "2020-10-23T22:30:27.341789Z"
    },
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def onehotize(x):\n",
    "    ind = np.arange(x.size)\n",
    "    out = np.zeros([x.size, 4])\n",
    "    out[ind, x] = 1\n",
    "    return out\n",
    "    \n",
    "\n",
    "def prep_data():\n",
    "    ntmdf = lut.unpickle('../data/ntm_data.pkl')[['sid', 'ntm', 'trial', 'lp1', 'lp2', 'lp3']]\n",
    "    ntmdf = ntmdf.loc[ntmdf.trial==0, ].reset_index(drop=True).drop(columns='trial')\n",
    "    ntmdf = ntmdf.rename(columns={'lp1': 'lpo1', 'lp2': 'lpo2', 'lp3': 'lpo3'}).set_index('sid')\n",
    "    \n",
    "    df = lut.unpickle('../data/trials_data2.pkl')\n",
    "    df = df.loc[(df.sid>=0) & (df.trial<=310), :]\n",
    "    calc_lp = lambda x: np.mean(x[-9:]) - np.mean(x[:10])\n",
    "\n",
    "    N = 250+15*4\n",
    "    with tqdm_notebook(total=df.sid.unique().shape[0]) as progbar:\n",
    "        sdf_out_list = []\n",
    "        for i, sdf_in in df.groupby('sid'):\n",
    "            sid = sdf_in.sid.values[0]\n",
    "            grp = sdf_in.grp.values[0]\n",
    "            t0  = sdf_in.t0.values[59:]\n",
    "            ntm, lpo1, lpo2, lpo3 = ntmdf.loc[sid, ].values\n",
    "            sdf_ind = [np.full(251, sid), np.full(251, grp), np.full(251, ntm), np.arange(0, 251), t0]\n",
    "            lpos = [np.full(251, lpo1), np.full(251, lpo2), np.full(251, lpo3)]\n",
    "            sdf_out = []\n",
    "            pc_cols = []\n",
    "            rlp_cols = []\n",
    "            dlp_cols = []\n",
    "            mlp_cols = []\n",
    "            relt_cols = []\n",
    "            ch_cols = []\n",
    "            for tid in [1, 2, 3, 4]:\n",
    "                nans = np.full(N, np.nan) # make NaN vector\n",
    "                pc = sdf_in.loc[sdf_in.t0==tid, 'cor'].dropna().astype('int').rolling(window=15).mean() # calculate rolling PC\n",
    "                nans[(sdf_in.t0==tid).values] = pc # fill nan vector with PC values where needed\n",
    "                pc_ = pc[:]\n",
    "                pc = pd.Series(nans).fillna(method='ffill')[59:] # fill NaNs with last non-NaN value and de-select initial NaNs\n",
    "                sdf_out.append(pc)\n",
    "                pc_cols.append('PC'+str(tid))\n",
    "\n",
    "                nans = np.full(N, np.nan) # make NaN vector\n",
    "                rlp = sdf_in.loc[sdf_in.t0==tid, 'cor'].dropna().astype('int').rolling(window=15).apply(calc_lp, raw=True) # calculate rolling PC\n",
    "                nans[(sdf_in.t0==tid).values] = rlp # fill nan vector with LP values where needed\n",
    "                rlp = pd.Series(nans).fillna(method='ffill')[59:] # fill NaNs with last non-NaN value and de-select initial NaNs        \n",
    "                sdf_out.append(rlp)\n",
    "                rlp_cols.append('rLP'+str(tid))\n",
    "\n",
    "                nans = np.full(N, np.nan) # make NaN vector\n",
    "                pc0ind = np.nonzero(~np.isnan(pc_.values.squeeze()))[0][0]\n",
    "                pc0 = pc_.values.squeeze()[pc0ind]\n",
    "                dlp = pc_.values.squeeze() - pc0\n",
    "                dlp[pc0ind] = pc0 - 0.5\n",
    "                nans[(sdf_in.t0==tid).values] = dlp\n",
    "                dlp = pd.Series(nans).fillna(method='ffill')[59:] # fill NaNs with last non-NaN value and de-select initial NaNs        \n",
    "                sdf_out.append(dlp)\n",
    "                dlp_cols.append('dLP'+str(tid))\n",
    "\n",
    "                nans = np.full(N, np.nan) # make NaN vector\n",
    "                l = sdf_in.loc[sdf_in.t0==tid, 'cor'].dropna().values.shape[0]\n",
    "                pc_ = sdf_in.loc[sdf_in.t0==tid, 'cor'].dropna().astype('int').rolling(min_periods=1,window=l).mean() # calculate rolling PC\n",
    "                pc0ind = np.nonzero(~np.isnan(pc_.values.squeeze()))[0][0]\n",
    "                pc0 = pc_.values.squeeze()[pc0ind]\n",
    "                mlp = pc_.values.squeeze() - pc0\n",
    "                mlp[pc0ind] = pc0 - 0.5\n",
    "                nans[(sdf_in.t0==tid).values] = mlp\n",
    "                mlp = pd.Series(nans).fillna(method='ffill')[59:] # fill NaNs with last non-NaN value and de-select initial NaNs        \n",
    "                sdf_out.append(mlp)\n",
    "                mlp_cols.append('mLP'+str(tid))\n",
    "\n",
    "            nvar = 4 # number of variables (e.g. PC, LP, CH etc)\n",
    "            inds = itertools.chain.from_iterable([np.arange(len(sdf_out)).tolist()[i::nvar] for i in range(nvar)])\n",
    "            colnames =  ['sid','grp','ntm','trial','tid']+['lpo1','lpo2','lpo3']+pc_cols+rlp_cols+dlp_cols+mlp_cols\n",
    "            list2stack = sdf_ind + lpos + [sdf_out[i] for i in inds]\n",
    "            sdf_out = pd.DataFrame(np.stack(list2stack, axis=1), columns=colnames)\n",
    "            dummies = onehotize(sdf_out.tid.values.astype(int)-1)\n",
    "            for j, tid in enumerate(list('1234')):\n",
    "                sdf_out['CH'+tid] = dummies[:, j]\n",
    "            for j, tid in enumerate(list('1234')):\n",
    "                sdf_out['RELT'+tid] = np.cumsum(sdf_out['CH'+tid]) / np.arange(1, 251+1)\n",
    "            sdf_out_list.append(sdf_out)\n",
    "            progbar.update()\n",
    "\n",
    "    df = pd.concat(sdf_out_list, ignore_index=True)\n",
    "    int_cols = ['sid', 'grp', 'trial', 'ntm', 'lpo1', 'lpo2', 'lpo3', 'CH1', 'CH2', 'CH3', 'CH4']\n",
    "    convert_dict = dict(zip(int_cols, [int for i in int_cols]))\n",
    "    df = df.astype(convert_dict) \n",
    "    with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "        display(df.loc[df.sid==0, 'PC1':'RELT4'].head())\n",
    "    \n",
    "#     lut.dopickle('data/choiceModelData_PC_dLP_rLP_mLP_RELT.pkl', data=df)\n",
    "\n",
    "    \n",
    "if 1:\n",
    "    prep_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Fit params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-23T22:34:35.036088Z",
     "start_time": "2020-10-23T22:34:28.163888Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def fit_params(Nseeds, lp_abs=True):\n",
    "    apply_bounds = False\n",
    "\n",
    "    bounds = OrderedDict({\n",
    "#         'intercept': [-1, 1],\n",
    "        'pc_coef':[-1, 1],\n",
    "#         'dlp_coef':[-1, 1],\n",
    "        'rlp_coef':[-1, 1],\n",
    "#         'relt_coef': [-1, 1],      \n",
    "        'tau':[1,10]})\n",
    "    func = np.abs if lp_abs else np.copy\n",
    "    \n",
    "    def rand_params(bounds):\n",
    "        return np.array([np.random.uniform(l, u) if bounds else np.random.rand() for l, u in bounds])\n",
    "    \n",
    "    def neg_log_likelihood(params, *args):\n",
    "        coeffs = np.array(params[:-1])\n",
    "        inps = np.stack(args[:-1], axis=0).astype(float)\n",
    "        U = (coeffs[:, None, None] * inps).sum(axis=0)\n",
    "        exponent = np.exp(U * params[-1])\n",
    "        P = (exponent.T / np.sum(exponent, axis=1)).T\n",
    "        logP = np.log(P[args[-1].astype(bool)])\n",
    "        logL = np.sum(logP, axis=0)\n",
    "        return -logL\n",
    "\n",
    "    # Estimate the params\n",
    "    df = lut.unpickle('data/choiceModelData_PC_dLP_rLP_mLP_RELT.pkl')\n",
    "    df = df.loc[df.ntm != 0, :]\n",
    "    print(df.sid.unique().size)\n",
    "    display(df.head())\n",
    "\n",
    "    arr = []\n",
    "\n",
    "    for seed in tqdm_notebook(range(Nseeds), desc='Seed:'):\n",
    "        np.random.seed(seed)\n",
    "        data_dict = {'sid': [], 'grp': [], 'ntm': [], 'loss': [], 'aic': [], 'aic_0': [], 'aic_diff': []}\n",
    "        for k in bounds.keys(): data_dict[k] = []\n",
    "\n",
    "        init_guess = rand_params([bound for bound in bounds.values()])\n",
    "        for i, sdf in tqdm_notebook(df.groupby('sid'), desc='sid:', leave=False):\n",
    "            sid, grp, ntm = sdf.sid.values[0], sdf.grp.values[0], sdf.ntm.values[0]\n",
    "            pcs = sdf.loc[:, 'PC1':'PC4'].values[1:, :].astype(float)\n",
    "            dlps = func(sdf.loc[:, 'dLP1':'dLP4'].values[1:, :].astype(float))\n",
    "            rlps = func(sdf.loc[:, 'rLP1':'rLP4'].values[1:, :].astype(float))\n",
    "            relts = sdf.loc[:, 'RELT1':'RELT4'].values[1:, :]\n",
    "            chs = sdf.loc[:, 'CH1':'CH4'].values[1:, :]\n",
    "\n",
    "            data = {'pc_coef':pcs, 'dlp_coef':dlps, 'rlp_coef':rlps, '' 'tau':chs}\n",
    "            data = tuple([data[k] for k in bounds.keys()])\n",
    "            data_arr = np.stack(data, axis=0)\n",
    "\n",
    "            if apply_bounds:\n",
    "                x, f, d = sp.optimize.fmin_l_bfgs_b(func=neg_log_likelihood, x0=init_guess, args=data,\n",
    "                                                approx_grad=True, disp=False, bounds=tuple(bounds.values()))\n",
    "            else:\n",
    "                res = sp.optimize.minimize(neg_log_likelihood, x0=init_guess, args=data)\n",
    "                x, f = res.x, res.fun\n",
    "                if np.isnan(f): f = 10e5\n",
    "\n",
    "            baseline = neg_log_likelihood([0 for k in bounds.keys()], *data)\n",
    "\n",
    "            # Store params   \n",
    "            data_dict['sid'].append(sid)\n",
    "            data_dict['grp'].append(grp)\n",
    "            data_dict['ntm'].append(ntm)\n",
    "            data_dict['loss'].append(f)\n",
    "            for i, k in enumerate(bounds.keys()):\n",
    "                data_dict[k].append(x[i])\n",
    "            data_dict['aic'].append(2*f + 2*len(bounds.keys()))\n",
    "            data_dict['aic_0'].append(2*baseline)\n",
    "            data_dict['aic_diff'].append(data_dict['aic_0'][-1] - data_dict['aic'][-1])\n",
    "\n",
    "        arr.append(pd.DataFrame(data_dict).values)\n",
    "\n",
    "    arr = np.stack(arr, axis=0)\n",
    "    signedFlag = 'unsigned' if lp_abs else 'signed'\n",
    "#     lut.dopickle('data/choiceModelParamFits_PC_rLP_{}_{}seeds'.format(signedFlag, Nseeds), data=arr)\n",
    "\n",
    "    \n",
    "if 1: \n",
    "    fit_params(500, lp_abs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Model comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-23T22:35:48.109718Z",
     "start_time": "2020-10-23T22:35:43.687013Z"
    },
    "code_folding": [],
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def model_comparison(Nseeds):\n",
    "    def rand_params(bounds):\n",
    "        return np.array([np.random.uniform(l, u) if bounds else np.random.rand() for l, u in bounds])\n",
    "    def neg_log_likelihood(params, *args):\n",
    "        coeffs = np.array(params[:-1])\n",
    "        inps = np.stack(args[:-1], axis=0)\n",
    "        U = (coeffs[:, None, None] * inps).sum(axis=0)\n",
    "        exponent = np.exp(U * params[-1])\n",
    "        P = (exponent.T / np.sum(exponent, axis=1)).T\n",
    "        logP = np.log(P[args[-1].astype(bool)])\n",
    "        logL = np.sum(logP, axis=0)\n",
    "        return -logL\n",
    "\n",
    "    # Estimate the params\n",
    "    df = lut.unpickle('../data/choiceModelData_PC_dLP_rLP_mLP_RELT.pkl')\n",
    "#     df = df.loc[df.ntm != 0, :]\n",
    "    df = df.loc[(df.ntm != 0) & (df.sid >= 216), :]\n",
    "\n",
    "    cols = ['form','sid','grp','ntm','loss','aic','tau']\n",
    "    varlist = ['PC', 'dLP', 'rLP', 'mLP', 'RELT']\n",
    "    for var in varlist: cols.append(var.lower()+'_coef')\n",
    "    varnames = np.array(varlist)\n",
    "\n",
    "    bounds = OrderedDict({\n",
    "        'pc_coef':[-1, 1],\n",
    "        'dlp_coef':[-1, 1],\n",
    "        'rlp_coef':[-1, 1],\n",
    "        'mlp_coef': [-1, 1],\n",
    "        'relt_coef': [-1, 1],\n",
    "        'tau':[1,10]})\n",
    "    \n",
    "    models, inds = [], [i for i in range(len(varlist))]\n",
    "    \n",
    "    for s in range(1,len(inds)+1):\n",
    "        models += combinations(inds, s)\n",
    "    \n",
    "    pb_label = wid.Label('Model form: ')\n",
    "    display(pb_label)\n",
    "    for i, sdf in tqdm_notebook(df.groupby('sid')):\n",
    "        data_dict = dict(zip(cols, [[] for _ in cols]))\n",
    "        sid, grp, ntm = sdf.sid.values[0], sdf.grp.values[0], sdf.ntm.values[0]\n",
    "        pcs = sdf.loc[:, 'PC1':'PC4'].values[1:, :].astype(float)\n",
    "        dlps = np.abs(sdf.loc[:, 'dLP1':'dLP4'].values[1:, :].astype(float))\n",
    "        rlps = np.abs(sdf.loc[:, 'rLP1':'rLP4'].values[1:, :].astype(float))\n",
    "        mlps = np.abs(sdf.loc[:, 'mLP1':'mLP4'].values[1:, :].astype(float))\n",
    "        relts = sdf.loc[:, 'RELT1':'RELT4'].values[1:, :]\n",
    "        chs = sdf.loc[:, 'CH1':'CH4'].values[1:, :]\n",
    "\n",
    "        data = {'pc_coef':pcs, 'dlp_coef':dlps, 'rlp_coef':rlps, 'mlp_coef':mlps, 'relt_coef': relts, 'tau':chs}\n",
    "        data_tuple = tuple([data[k] for k in bounds.keys()])\n",
    "        data_arr = np.stack(data, axis=0)\n",
    "\n",
    "        for model in models:\n",
    "            subdata = [data_tuple[mi] for mi in model] + [data_tuple[-1]]\n",
    "            xs, fs = [], []\n",
    "            pb_label.value = 'Model form: {}'.format(' + '.join(varnames[tuple([model])]))\n",
    "            for seed in tqdm_notebook(range(Nseeds), leave=False):\n",
    "                init_guess = rand_params(list(bounds.values())).tolist()\n",
    "                subguess = [init_guess[mi] for mi in model] + [init_guess[-1]]\n",
    "                res = sp.optimize.minimize(neg_log_likelihood, x0=subguess, args=tuple(subdata))\n",
    "                xs.append(res.x)\n",
    "                fs.append(res.fun)\n",
    "            if np.all(np.isnan(fs)):\n",
    "                print('\"ValueError: All-NaN slice encountered\" error, skipped')\n",
    "                continue\n",
    "            x, f = xs[np.nanargmin(fs)], np.nanmin(fs)\n",
    "\n",
    "            # Store params\n",
    "            vec = np.full(len(varlist)+1, np.nan)\n",
    "            vec[tuple([model])] = x[:-1]\n",
    "            vec[-1] = x[-1]\n",
    "            data_dict['form'].append(' + '.join(varnames[tuple([model])]))\n",
    "            data_dict['sid'].append(sid)\n",
    "            data_dict['grp'].append(grp)\n",
    "            data_dict['ntm'].append(ntm)\n",
    "            data_dict['loss'].append(f)\n",
    "            data_dict['aic'].append(2*f + 2*len(models))\n",
    "            for i, k in enumerate(list(bounds.keys())):\n",
    "                data_dict[k].append(vec[i])\n",
    "        \n",
    "        # Calculate parameter stats\n",
    "        fdf = pd.DataFrame(data_dict)\n",
    "        if sid==0:\n",
    "            fdf.to_csv('data/choiceModelComparison_PC_dLP_rLP_mLP_RELT_{}seeds.csv'.format(Nseeds), \n",
    "                       index=False)\n",
    "        else:\n",
    "            fdf.to_csv('data/choiceModelComparison_PC_dLP_rLP_mLP_RELT_{}seeds.csv'.format(Nseeds), \n",
    "                       index=False, mode='a', header=False)\n",
    "\n",
    "    \n",
    "\n",
    "if 1: \n",
    "    model_comparison(300)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
